Pixel screening based intermediate correction for blind deblurring.
When Does Contrastive Visual Representation Learning Work?
Large-Scale Pre-training for Person Re-identification with Noisy Labels.
Clipped Hyperbolic Classifiers Are Super-Hyperbolic Classifiers.
CO-SNE: Dimensionality Reduction and Visualization for Hyperbolic Data.
Efficient Deep Embedded Subspace Clustering.
Noise Is Also Useful: Negative Correlation-Steered Latent Contrastive Learning.
Active Learning for Open-set Annotation.
Understanding and Increasing Efficiency of Frank-Wolfe Adversarial Training.
Robust Optimization as Data Augmentation for Large-scale Graphs.
A Re-Balancing Strategy for Class-Imbalanced Classification Based on Instance Difficulty.
The Devil is in the Margin: Margin-based Label Smoothing for Network Calibration.
Towards Better Plasticity-Stability Trade-off in Incremental Learning: A Simple Linear Connector.
GCR: Gradient Coreset based Replay Buffer Selection for Continual Learning.
Learning Bayesian Sparse Networks with Full Experience Replay for Continual Learning.
A variational Bayesian method for similarity learning in non-rigid image registration.
Learning to Learn by Jointly Optimizing Neural Architecture and Weights.
Learning to Prompt for Continual Learning.
Meta-attention for ViT-backed Continual Learning.
Multi-Frame Self-Supervised Depth with Transformers.
Continual Learning with Lifelong Vision Transformer.
Rethinking Bayesian Deep Learning Methods for Semi-Supervised Volumetric Medical Image Segmentation.
Revisiting Random Channel Pruning for Neural Network Compression.
Deep Safe Multi-view Clustering: Reducing the Risk of Clustering Performance Degradation Caused by View Increase.
Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning.
Towards Robust and Reproducible Active Learning using Neural Networks.
Non-Iterative Recovery from Nonlinear Observations using Generative Models.
Gaussian Process Modeling of Approximate Inference Errors for Variational Autoencoders.
Robust Combination of Distributed Gradients Under Adversarial Perturbations.
Do learned representations respect causal relationships?
How Much More Data Do I Need? Estimating Requirements for Downstream Tasks.
Pushing the Envelope of Gradient Boosting Forests via Globally-Optimized Oblique Trees.
Contrastive Test-Time Adaptation.
AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation.
Selective-Supervised Contrastive Learning with Noisy Labels.
RecDis-SNN: Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks.
Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction.
Scalable Penalized Regression for Noise Detection in Learning with Noisy Labels.
Nested Hyperbolic Spaces for Dimensionality Reduction and Hyperbolic NN Design.
Learning Structured Gaussians to Approximate Deep Ensembles.
Out-of-distribution Generalization with Causal Invariant Transformations.
Split Hierarchical Variational Compression.
Implicit Feature Decoupling with Depthwise Quantization.
Understanding Uncertainty Maps in Vision with Statistical Testing.
A Hybrid Quantum-Classical Algorithm for Robust Fitting.
A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching.
FastDOG: Fast Discrete Optimization on GPU.
Data-Free Network Compression via Parametric Non-uniform Mixed Precision Quantization.
AdaSTE: An Adaptive Straight-Through Estimator to Train Binary Neural Networks.
GLASS: Geometric Latent Augmentation for Shape Spaces.
Training Quantised Neural Networks with STE Variants: the Additive Noise Annealing Algorithm.
AME: Attention and Memory Enhancement in Hyper-Parameter Optimization.
Efficient Maximal Coding Rate Reduction by Variational Forms.
A Unified Framework for Implicit Sinkhorn Differentiation.
Computing Wasserstein-$p$ Distance Between Images with Linear Cost.
An Iterative Quantum Approach for Transformation Estimation from Point Sets.
BoosterNet: Improving Domain Generalization of Deep Neural Nets using Culpability-Ranked Features.
Pooling Revisited: Your Receptive Field is Suboptimal.
Why Discard if You can Recycle?: A Recycling Max Pooling Module for 3D Point Cloud Analysis.
Online Convolutional Reparameterization.
RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality.
DyRep: Bootstrapping Training with Dynamic Re-parameterization.
Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free.
Condensing CNNs with Partial Differential Equations.
Deep Equilibrium Optical Flow Estimation.
Frame Averaging for Equivariant Shape Space Learning.
Dual-Generator Face Reenactment.
Convolution of Convolution: Let Kernels Spatially Collaborate.
SASIC: Stereo Image Compression with Latent Shifts and Stereo Attention.
RADU: Ray-Aligned Depth Update Convolutions for ToF Data Denoising.
Co-domain Symmetry for Complex-Valued Deep Learning.
Paramixer: Parameterizing Mixing Links in Sparse Factors Works Better than Dot-Product Self-Attention.
Compressing Models with Few Samples: Mimicking then Replacing.
Total Variation Optimization Layers for Computer Vision.
AIM: an Auto-Augmenter for Images and Meshes.
Recurrent Variational Network: A Deep Learning Inverse Problem Solver applied to the task of Accelerated MRI Reconstruction.
Deep orientation-aware functional maps: Tackling symmetry issues in Shape Matching.
Weakly-supervised Metric Learning with Cross-Module Communications for the Classification of Anterior Chamber Angle Images.
Delving into the Estimation Shift of Batch Normalization in a Network.
Generalizing Interactive Backpropagating Refinement for Dense Prediction Networks.
Brain-inspired Multilayer Perceptron with Spiking Neurons.
Smooth Maximum Unit: Smooth Activation Function for Deep Networks using Smoothing Maximum Technique.
Revisiting Weakly Supervised Pre-Training of Visual Perception Models.
On the Integration of Self-Attention and Convolution.
Hire-MLP: Vision MLP via Hierarchical Rearrangement.
Stable Long-Term Recurrent Video Super-Resolution.
Single-Domain Generalized Object Detection in Urban Scene via Cyclic-Disentangled Self-Distillation.
Progressive End-to-End Object Detection in Crowded Scenes.
Zero-Shot Text-Guided Object Generation with Dream Fields.
ISNet: Shape Matters for Infrared Small Target Detection.
Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving.
CLRNet: Cross Layer Refinement Network for Lane Detection.
CAT-Det: Contrastively Augmented Transformer for Multimodal 3D Object Detection.
Modality-Agnostic Learning for Radar-Lidar Fusion in Vehicle Detection.
Group Contextualization for Video Recognition.
Learning Transferable Human-Object Interaction Detector with Natural Language Supervision.
Accelerating DETR Convergence via Semantic-Aligned Matching.
Efficient Video Instance Segmentation via Tracklet Query and Proposal.
Class Re-Activation Maps for Weakly-Supervised Semantic Segmentation.
Democracy Does Matter: Comprehensive Feature Mining for Co-Salient Object Detection.
C2AM: Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation.
Sketching without Worrying: Noise-Tolerant Sketch-Based Image Retrieval.
AutoLoss-Zero: Searching Loss Functions from Scratch for Generic Tasks.
Consistency Learning via Decoding Path Augmentation for Transformers in Human Object Interaction Detection.
A Proposal-based Paradigm for Self-supervised Sound Source Localization in Videos.
SimAN: Exploring Self-Supervised Representation Learning of Scene Text via Similarity-Aware Normalization.
Towards End-to-End Unified Scene Text Detection and Layout Analysis.
Clothes-Changing Person Re-identification with RGB Modality Only.
MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection.
Homography Loss for Monocular 3D Object Detection.
TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers.
TWIST: Two-Way Inter-label Self-Training for Semi-supervised 3D Instance Segmentation.
RBGNet: Ray-based Grouping for 3D Object Detection.
Voxel Field Fusion for 3D Object Detection.
Learning to Detect Mobile Objects from LiDAR Scans Without Labels.
OccAM's Laser: Occlusion-based Attribution Maps for 3D Object Detectors on LiDAR Data.
Confidence Propagation Cluster: Unleash Full Potential of Object Detectors.
TransGeo: Transformer Is All You Need for Cross-view Image Geo-localization.
A Voxel Graph CNN for Object Classification with Event Cameras.
OSKDet: Orientation-sensitive Keypoint Localization for Rotated Object Detection.
Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes.
Category Contrast for Unsupervised Domain Adaptation in Visual Tasks.
Scaling Vision Transformers.
Amodal Segmentation through Out-of-Task and Out-of-Distribution Generalization with a Bayesian Model.
GANSeg: Learning to Segment by Unsupervised Hierarchical Image Generation.
Segment-Fusion: Hierarchical Context Fusion for Robust 3D Semantic Segmentation.
Deep Hierarchical Semantic Segmentation.
Semantic Segmentation by Early Region Proxy.
Panoptic, Instance and Semantic Relations: A Relational Context Encoder to Enhance Panoptic Segmentation.
Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with Transformers.
Masked-attention Mask Transformer for Universal Image Segmentation.
FocalClick: Towards Practical Interactive Image Segmentation.
High Quality Segmentation for Ultra High-resolution Images.
Wnet: Audio-Guided Video Object Segmentation via Wavelet-Based Cross- Modal Denoising Networks.
Recurrent Dynamic Embedding for Video Object Segmentation.
Accelerating Video Object Segmentation with Compressed Video.
Per-Clip Video Object Segmentation.
SWEM: Towards Real-Time Video Object Segmentation with Sequential Weighted Expectation-Maximization.
Neural Recognition of Dashed Curves with Gestalt Law of Continuity.
CVNet: Contour Vibration Network for Building Extraction.
A Keypoint-based Global Association Network for Lane Detection.
EDTER: Edge Detection with Transformer.
Fixing Malfunctional Objects With Learned Physical Simulation and Functional Prediction.
Coherent Point Drift Revisited for Non-rigid Shape Matching and Registration.
CodedVTR: Codebook-based Sparse Voxel Transformer with Geometric Guidance.
FLOAT: Factorized Learning of Object Attributes for Improved Multi-object Multi-part Scene Parsing.
Rotationally Equivariant 3D Object Detection.
AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis.
Learning to Estimate Robust 3D Human Mesh from In-the-Wild Crowded Scenes.
Human Mesh Recovery from Multiple Shots.
HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network.
Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing.
Disentangled3D: Learning a 3D Generative Model with Disentangled Geometry and Appearance from Monocular Images.
NeuralHDHair: Automatic High-fidelity Hair Modeling from a Single Image Using Implicit Neural Representations.
Topologically-Aware Deformation Fields for Single-View 3D Reconstruction.
Generating Diverse 3D Reconstructions from a Single Occluded Face Image.
LOLNeRF: Learn from One Look.
Learning Local Displacements for Point Cloud Completion.
Exploiting Pseudo Labels in a Self-Supervised Learning Framework for Improved Monocular Depth Estimation.
Dimension Embeddings for Monocular 3D Object Detection.
Understanding 3D Object Articulation in Internet Videos.
P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior.
Neural Face Identification in a 2D Wireframe Projection of a Manifold Object.
PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation.
Stability-driven Contact Reconstruction From Monocular Color Images.
LGT-Net: Indoor Panoramic Room Layout Estimation with Geometry-Aware Transformer Network.
Collaborative Learning for Hand and Object Reconstruction with Attention-guided Graph Convolution.
RM-Depth: Unsupervised Learning of Recurrent Monocular Depth in Dynamic Scenes.
Exploring Geometric Consistency for Monocular 3D Object Detection.
Learning 3D Object Shape and Layout without 3D Supervision.
Single-Stage 3D Geometry-Preserving Depth Estimation Model Training on Dataset Mixtures with Uncalibrated Stereo Data.
Occluded Human Mesh Recovery.
LAKe-Net: Topology-Aware Point Cloud Completion by Localizing Aligned Keypoints.
OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction.
Depth Estimation by Combining Binocular Stereo and Monocular Structured-Light.
Learning from Pixel-Level Noisy Label : A New Perspective for Light Field Saliency Detection.
HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening.
Revisiting Near/Remote Sensing with Geospatial Attention.
Memory-augmented Deep Conditional Unfolding Network for Pansharpening.
Mutual Information-driven Pan-sharpening.
Sparse and Complete Latent Organization for Geospatial Semantic Segmentation.
The Probabilistic Normal Epipolar Constraint for Frame- To-Frame Rotation Optimization under Uncertain Feature Positions.
Oriented RepPoints for Aerial Object Detection.
Using 3D Topological Connectivity for Ghost Particle Reduction in Flow Reconstruction.
Self-Supervised Super-Resolution for Multi-Exposure Push-Frame Satellites.
MISF: Multi-level Interactive Siamese Filtering for High-Fidelity Image Inpainting.
Iterative Deep Homography Estimation.
GCFSR: a Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors.
Deep Color Consistent Network for Low-Light Image Enhancement.
LAR-SR: A Local Autoregressive Model for Image Super-Resolution.
Multi-Scale Memory-Based Video Deblurring.
Local Texture Estimator for Implicit Representation Function.
ChiTransformer: Towards Reliable Stereo from Cues.
PolyWorld: Polygonal Building Extraction with Graph Neural Networks in Satellite Images.
BNUDC: A Two-Branched Deep Neural Network for Restoring Images from Under-Display Cameras.
ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior.
IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation.
Learning Graph Regularisation for Guided Super-Resolution.
Self-supervised Deep Image Restoration via Adaptive Stochastic Gradient Langevin Dynamics.
Self-Supervised Arbitrary-Scale Point Clouds Upsampling via Implicit Neural Representation.
Noise Distribution Adaptive Self-Supervised Image Denoising using Tweedie Distribution and Score Matching.
Unpaired Deep Image Deraining Using Dual Contrastive Learning.
Blind2Unblind: Self-Supervised Image Denoising with Visible Blind Spots.
Self-augmented Unpaired Image Dehazing via Density and Depth Decomposition.
VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution.
Fast Algorithm for Low-rank Tensor Completion in Delay-embedded Space.
Exploring and Evaluating Image Restoration Potential in Dynamic Scenes.
GIQE: Generic Image Quality Enhancement via NthOrder Iterative Degradation.
Does text attract attention on e-commerce images: A novel saliency prediction dataset and method.
IDR: Self-Supervised Image Denoising via Iterative Data Refinement.
ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo.
Texture-based Error Analysis for Image Super-Resolution.
Blind Image Super-resolution with Elaborate Degradation Modeling on Noise and Kernel.
KNN Local Attention for Image Restoration.
Can You Spot the Chameleon? Adversarially Camouflaging Images from Co-Salient Object Detection.
Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection.
Self-Supervised Keypoint Discovery in Behavioral Videos.
Learning to Align Sequential Actions in the Wild.
Dynamic 3D Gaze from Afar: Deep Gaze Estimation from Temporal Eye-Head-Body Coordination.
End-to-End Human-Gaze-Target Detection with Transformers.
Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis.
MUSE-VAE: Multi-Scale VAE for Environment-Aware Long Term Trajectory Prediction.
Graph-based Spatial Transformer with Memory Replay for Multi-future Pedestrian Trajectory Prediction.
End-to-End Trajectory Distribution Prediction Based on Occupancy Grid Maps.
Learning Affordance Grounding from Exocentric Images.
3D Scene Painting via Semantic Image Synthesis.
Learning Invisible Markers for Hidden Codes in Offline-to-online Photography.
ETHSeg: An Amodel Instance Segmentation Network and a Real-world Dataset for X-Ray Waste Inspection.
Doodle It Yourself: Class Incremental Learning by Drawing a Few Sketches.
Image Disentanglement Autoencoder for Steganography without Embedding.
Adaptive Hierarchical Representation Learning for Long-Tailed Object Detection.
Semiconductor Defect Detection by Hybrid Classical-Quantum Deep Learning.
Density-preserving Deep Point Cloud Compression.
Graph-context Attention Networks for Size-varied Deep Graph Matching.
TransWeather: Transformer-based Restoration of Images Degraded by Adverse Weather Conditions.
ObjectFormer for Image Manipulation Detection and Localization.
Sequential Voting with Relational Box Fields for Active Object Detection.
Efficient Classification of Very Large Images with Tiny Objects.
Partially Does It: Towards Scene-Level FG-SBIR with Partial Input.
Long-term Visual Map Sparsification with Heterogeneous GNN.
Connecting the Complementary-view Videos: Joint Camera Identification and Subject Association.
DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation.
Aesthetic Text Logo Synthesis via Content-aware Layout Inferring.
Rethinking Image Cropping: Exploring Diverse Compositions from Global Views.
Defensive Patches for Robust Recognition in the Physical World.
Semi-supervised Video Paragraph Grounding with Contrastive Encoder.
Meta Distribution Alignment for Generalizable Person Re-Identification.
FvOR: Robust Joint Shape and Pose Optimization for Few-view Object Reconstruction.
It's About Time: Analog Clock Reading in the Wild.
Consistency driven Sequential Transformers Attention Model for Partially Observable Scenes.
Smartadapt: Multi-branch Object Detection Framework for Videos on Mobiles.
Generating 3D Bio-Printable Patches Using Wound Segmentation and Reconstruction to Treat Diabetic Foot Ulcers.
Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving.
CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation.
Unsupervised Hierarchical Semantic Segmentation with Multiview Cosegmentation and Clustering Transformers.
Rethinking Semantic Segmentation: A Prototype View.
Semantic-Aware Domain Generalized Segmentation.
Adaptive Early-Learning Correction for Segmentation from Noisy Annotations.
Pointly-Supervised Instance Segmentation.
Joint Forecasting of Panoptic Segmentations with Difference Attention.
FocusCut: Diving into a Focus View in Interactive Segmentation.
Human Instance Matting via Mutual Guidance and Multi-Instance Refinement.
Deformable Sprites for Unsupervised Video Decomposition.
Eigencontours: Novel Contour Descriptors Based on Low-Rank Approximation.
Robust and Accurate Superquadric Recovery: a Probabilistic Approach.
Medial Spectral Coordinates for 3D Shape Analysis.
Scribble-Supervised LiDAR Semantic Segmentation.
SoftGroup for 3D Instance Segmentation on Point Clouds.
Accurate 3D Body Shape Regression using Metric and Semantic Attributes.
JIFF: Jointly-aligned Implicit Face Function for High Quality Single View Clothed Human Reconstruction.
Tracking People by Predicting 3D Appearance, Location and Pose.
ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation via Online Exploration and Synthesis.
Interacting Attention Graph for Single Image Two-Hand Reconstruction.
3D human tongue reconstruction from single "in-the-wild" images.
EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation.
Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular 3D Object Detection.
OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion.
Gated2Gated: Self-Supervised Depth Estimation from Gated Images.
IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes.
Egocentric Scene Understanding via Multimodal Spatial Rectifier.
Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry.
The Implicit Values of A Good Hand Shake: Handheld Multi-Frame Neural Depth Refinement.
BANMo: Building Animatable 3D Neural Models from Many Casual Videos.
Self-supervised Video Transformer.
Temporally Efficient Vision Transformer for Video Instance Segmentation.
VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation.
Temporal Alignment Networks for Long-term Video.
Revisiting the "Video" in Video-Language Understanding.
Invariant Grounding for Video Question Answering.
P3IV: Probabilistic Procedure Planning from Instructional Videos with Weak Supervision.
FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality Assessment.
Cross-Model Pseudo-Labeling for Semi-Supervised Action Recognition.
Revisiting Skeleton-based Action Recognition.
OpenTAL: Towards Open Set Temporal Action Localization.
Dual-AI: Dual-path Actor Interaction Learning for Group Activity Recognition.
TransRank: Self-supervised Video Representation Learning via Ranking-based Transformation Recognition.
Revealing Occlusions with 4D Neural Fields.
HODOR: High-level Object Descriptors for Object Re-segmentation in Video Learned from Static Images.
Compositional Temporal Grounding with Structured Variational Cross-Graph Correspondence Learning.
UMT: Unified Multi-modal Transformers for Joint Video Moment Retrieval and Highlight Detection.
Future Transformer for Long-term Action Anticipation.
MLP-3D: A MLP-like 3D Architecture with Grouped Time Mixing.
Learning Pixel-Level Distinctions for Video Highlight Detection.
DR.VIC: Decomposition and Reasoning for Video Individual Counting.
Slot-VPS: Object-centric Representation Learning for Video Panoptic Segmentation.
Explore Spatio-temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline.
Video Shadow Detection via Spatio-Temporal Interpolation Consistency Training.
Coarse-to-Fine Feature Mining for Video Semantic Segmentation.
Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation.
Object-Region Video Transformers.
Colar: Effective and Efficient Online Action Detection by Consulting Exemplars.
SimVP: Simpler yet Better Video Prediction.
Imposing Consistency for Optical Flow Estimation.
Stand-Alone Inter-Frame Attention in Video Models.
Video Swin Transformer.
Bayesian Nonparametric Submodular Video Partition for Robust Anomaly Detection.
Likert Scoring with Grade Decoupling for Long-term Action Assessment.
Complex Video Action Reasoning via Learnable Markov Logic Network.
Learning from Temporal Gradient for Semi-supervised Action Recognition.
Semi-Supervised Video Semantic Segmentation with Inter-Frame Feature Reconstruction.
Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation.
Joint Hand Motion and Interaction Hotspots Prediction from Egocentric Videos.
Human Hands as Probes for Interactive Object Understanding.
LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition.
Object-aware Video-language Pre-training for Retrieval.
Fast and Unsupervised Action Boundary Detection for Action Segmentation.
Multiview Transformers for Video Recognition.
Semi-Weakly-Supervised Learning of Complex Actions from Instructional Task Videos.
Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection.
Comparing Correspondences: Video Prediction with Correspondence-wise Losses.
Sound-Guided Semantic Image Manipulation.
Expressive Talking Head Generation with Granular Audio-Visual Control.
Depth-Aware Generative Adversarial Network for Talking Head Video Generation.
Learning Motion-Dependent Appearance for High-Fidelity Rendering of Dynamic Humans from a Single Camera.
Audio-driven Neural Gesture Reenactment with Video Motion Graphs.
Portrait Eyeglasses and Shadow Removal by Leveraging 3D Synthetic Data.
Weakly Supervised High-Fidelity Clothing Model Generation.
TemporalUV: Capturing Loose Clothing with Temporally Coherent UV Coordinates.
Full-Range Virtual Try-On with Recurrent Tri-Level Transform.
Style-Based Global Appearance Flow for Virtual Try-On.
Dressing in the Wild by Watching Dance Videos.
A Brand New Dance Partner: Music-Conditioned Pluralistic Dancing Controlled by Multiple Dance Genres.
Unpaired Cartoon Image Synthesis via Gated Cycle Mapping.
DLFormer: Discrete Latent Transformer for Video Inpainting.
ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation.
Video Frame Interpolation with Transformer.
Long-term Video Frame Interpolation via Feature Propagation.
Many-to-many Splatting for Efficient Video Frame Interpolation.
Look Outside the Room: Synthesizing A Consistent Long-Term 3D Scene Video from A Single Image.
Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning.
Playable Environments: Video Manipulation in Space and Time.
Event-based Video Reconstruction via Potential-assisted Spiking Neural Network.
Modular Action Concept Grounding in Semantic Video Prediction.
Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning.
StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2.
Structure-Aware Motion Transfer with Deformable Anchor Model.
Image Animation with Perturbed Masks.
Thin-Plate Spline Motion Model for Image Animation.
Controllable Animation of Fluid Elements in Still Images.
Watch It Move: Unsupervised Discovery of 3D Joints for Re-Posing of Articulated Objects.
Geometric Structure Preserving Warp for Natural Image Stitching.
Few-Shot Incremental Learning for Label-to-Image Translation.
Exemplar-based Pattern Synthesis with Implicit Periodic Field Network.
SIMBAR: Single Image-Based Scene Relighting For Effective Data Augmentation For Automated Driving Vision Tasks.
SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage.
PILC: Practical Image Lossless Compression with an End-to-end GPU Oriented Neural Framework.
Kubric: A scalable dataset generator.
360MonoDepth: High-Resolution 360° Monocular Depth Estimation.
Pretrain, Self-train, Distill: A simple recipe for Supersizing 3D Reconstruction.
DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation.
MonoGround: Detecting Monocular 3D Objects from the Ground.
3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow.
Toward Practical Monocular Indoor Depth Estimation.
Focal Length and Object Pose Estimation via Render and Compare.
CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields.
Registering Explicit to Implicit: Towards High-Fidelity Garment mesh Reconstruction from Single Images.
Layered Depth Refinement with Mask Guidance.
HEAT: Holistic Edge Attention Transformer for Structured Reconstruction.
BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed Information.
Time3D: End-to-End Joint Monocular 3D Object Detection and Tracking for Autonomous Driving.
What's in your hands? 3D Reconstruction of Generic Objects in Hands.
3D Moments from Near-Duplicate Photos.
Neural Window Fully-connected CRFs for Monocular Depth Estimation.
PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors.
CroMo: Cross-Modal Learning for Monocular Depth Estimation.
$\phi$-SfT: Shape-from-Template with a Physics-Based Deformation Model.
Human-Aware Object Placement for Visual Environment Reconstruction.
AutoRF: Learning 3D Object Radiance Fields from Single View Observations.
Pix2NeRF: Unsupervised Conditional $\pi$-GAN for Single Image to Neural Radiance Fields Translation.
MonoScene: Monocular 3D Semantic Scene Completion.
GenDR: A Generalized Differentiable Renderer.
MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer.
ROCA: Robust CAD Model Retrieval and Alignment from a Single Image.
HP-Capsule: Unsupervised Face Part Discovery by Hierarchical Parsing Capsule Network.
Killing Two Birds with One Stone: Efficient and Robust Training of Face Recognition CNNs by Partial FC.
Sparse Local Patch Transformer for Robust Face Alignment and Landmarks Inherent Relation Learning.
Enhancing Face Recognition with Self-Supervised 3D Reconstruction.
Learning to Learn across Diverse Data Biases in Deep Face Recognition.
An Efficient Training Approach for Very Large Scale Face Recognition.
MogFace: Towards a Deeper Appreciation on Face Detection.
Exploring Frequency Adversarial Attacks for Face Forgery Detection.
End-to-End Reconstruction-Classification Learning for Face Forgery Detection.
Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing.
Privacy-preserving Online AutoML for Domain-Specific Face Detection.
Simulated Adversarial Testing of Face Recognition Models.
Decoupled Multi-task Learning with Cyclical Self-Regulation for Face Parsing.
Towards Semi-Supervised Deep Facial Expression Recognition with An Adaptive Confidence Margin.
Towards Accurate Facial Landmark Detection via Cascaded Transformers.
PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer.
GazeOnce: Real-Time Multi-Person Gaze Estimation.
Generalizing Gaze Estimation with Rotation Consistency.
Face Relighting with Geometrically Consistent Shadows.
HairMapper: Removing Hair from Portraits Using GANs.
Learning to Restore 3D Face from In-the-Wild Degraded Images.
Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels.
Perturbed and Strict Mean Teachers for Semi-supervised Semantic Segmentation.
ST++: Make Self-trainingWork Better for Semi-supervised Semantic Segmentation.
Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation via Semantic Knowledge Transfer and Self-Refinement.
Self-supervised Image-specific Prototype Exploration for Weakly Supervised Semantic Segmentation.
Regional Semantic Contrast and Aggregation for Weakly Supervised Semantic Segmentation.
Multi-class Token Transformer for Weakly Supervised Semantic Segmentation.
Weakly Supervised Semantic Segmentation by Pixel-to-Prototype Contrast.
Threshold Matters in WSSS: Manipulating the Activation for the Robust and Accurate Segmentation Model Against Thresholds.
Novel Class Discovery in Semantic Segmentation.
Pin the Memory: Learning to Generalize Semantic Segmentation.
ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-high Resolution Segmentation.
Incremental Learning in Semantic Segmentation from Image Labels.
Instance Segmentation with Mask-supervised Polygonal Boundary Transformers.
SharpContour: A Contour-based Boundary Refinement Approach for Efficient and Accurate Instance Segmentation.
Sparse Object-level Supervision for Instance Segmentation with Pixel Embeddings.
Mask Transfiner for High-Quality Instance Segmentation.
Open-World Instance Segmentation: Exploiting Pseudo Ground Truth From Learned Pairwise Affinity.
Sparse Instance Activation for Real-Time Instance Segmentation.
E2EC: An End-to-End Contour-based Method for High-Quality High-Speed Instance Segmentation.
Hyperbolic Image Segmentation.
SeeThroughNet: Resurrection of Auxiliary Loss by Preserving Class Probability Information.
CDGNet: Class Distribution Guided Network for Human Parsing.
CLIMS: Cross Language Image Matching for Weakly Supervised Semantic Segmentation.
Sparse Non-local CRF.
Detecting Camouflaged Object in Frequency Domain.
Progressive Minimal Path Method with Embedded CNN.
Open-Set Text Recognition via Character-Context Decoupling.
Neural Collaborative Graph Machines for Table Structure Recognition.
Revisiting Document Image Dewarping by Grid Regularization.
Syntax-Aware Network for Handwritten Mathematical Expression Recognition.
Few Could Be Better Than All: Feature Sampling and Grouping for Scene Text Detection.
Fourier Document Restoration for Robust Document Dewarping and Recognition.
XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich Document Understanding.
SwinTextSpotter: Scene Text Spotting via Better Synergy between Text Detection and Text Recognition.
Towards Weakly-Supervised Text Spotting using a Multi-Task Transformer.
TableFormer: Table Structure Understanding with Transformers.
Knowledge Mining with Scene Text for Fine-Grained Recognition.
PubTables-1M: Towards comprehensive table extraction from unstructured documents.
Focal and Global Knowledge Distillation for Detectors.
Speed up Object Detection on Gigapixel-level Images with Patch Arrangement.
Training Object Detectors from Scratch: An Empirical Study in the Era of Vision Transformer.
Learning with Neighbor Consistency for Noisy Labels.
Meta Convolutional Neural Networks for Single Domain Generalization.
Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification.
Geometry-Aware Guided Loss for Deep Crack Recognition.
Segment, Magnify and Reiterate: Detecting Camouflaged Objects the Hard Way.
Dynamic Sparse R-CNN.
Deep Hybrid Models for Out-of-Distribution Detection.
AutoLoss-GMS: Searching Generalized Margin-based Softmax Loss Function for Person Re-identification.
Feature Erasing and Diffusion Network for Occluded Person Re-Identification.
Multi-label Classification with Partial Annotations using Class-aware Selective Loss.
BoxeR: Box-Attention for 2D and 3D Transformers.
Multi-label Iterated Learning for Image Classification with Label Ambiguity.
Vision Transformer with Deformable Attention.
MViTv2: Improved Multiscale Vision Transformers for Classification and Detection.
Dense Learning based Semi-Supervised Object Detection.
R(Det)2: Randomized Decision Routing for Object Detection.
GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction.
Self-Supervised Equivariant Learning for Oriented Keypoint Detection.
Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification.
Object Localization under Single Coarse Point Supervision.
Rethinking Visual Geo-localization for Large-Scale Applications.
Whose Hands are These? Hand Detection and Hand-Body Association in the Wild.
Cloning Outfits from Real-World Images to 3D Characters for Generalizable Person Re-Identification.
Towards Unsupervised Domain Generalization.
ViM: Out-Of-Distribution with Virtual-logit Matching.
Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space.
Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation.
Align and Prompt: Video-and-Language Pre-training with Entity Prompts.
Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation.
Language as Queries for Referring Video Object Segmentation.
End-to-End Referring Video Object Segmentation with Multimodal Transformers.
Multi-Level Representation Learning with Semantic Alignment for Referring Video Object Segmentation.
X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval.
Video-Text Representation Learning via Differentiable Weak Temporal Alignment.
MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions.
Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions.
Measuring Compositional Consistency for Video Question Answering.
Sim VQA: Exploring Simulated Environments for Visual Question Answering.
Transform-Retrieve-Generate: Natural Language-Centric Outside-Knowledge Visual Question Answering.
SwapMix: Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering.
MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-based Visual Question Answering.
Maintaining Reasoning Consistency in Compositional Visual Question Answering.
MLSLT: Towards Multilingual Sign Language Translation.
A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation.
C2SLR: Consistency-enhanced Continuous Sign Language Recognition.
Signing at Scale: Learning to Co-Articulate Signs for Large-Scale Photo-Realistic Sign Language Production.
Generating Diverse and Natural 3D Human Motions from Text.
Sub-word Level Lip Reading With Visual Attention.
Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale.
ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval.
Cross Modal Retrieval with Querybank Normalisation.
Prompt Distribution Learning.
VALHALLA: Visual Hallucination for Machine Translation.
VL-ADAPTER: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks.
Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality.
MixFormer: Mixing Features across Windows and Dimensions.
Recurrent Glimpse-based Decoder for Detection with Transformer.
Mobile-Former: Bridging MobileNet and Transformer.
Unsupervised Domain Generalization by Learning a Bridge Across Domains.
SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection.
Target-Relevant Knowledge Preservation for Multi-Source Domain Adaptive Object Detection.
PNP: Robust Learning from Noisy Labels by Probabilistic Noise Prediction.
Few-Shot Object Detection with Fully Cross-Transformer.
Task Discrepancy Maximization for Fine-grained Few-Shot Classification.
Leveraging Self-Supervision for Cross-Domain Crowd Counting.
What to look at and where: Semantic and Spatial Refined Transformer for detecting human-object interactions.
AdaMixer: A Fast-Converging Query-Based Object Detector.
Correlation Verification for Image Retrieval.
Real-time Object Detection for Streaming Perception.
Deep Visual Geo-localization Benchmark.
RendNet: Unified 2D/3D Recognizer with Latent Space Rendering.
Sparse Fuse Dense: Towards High Quality 3D Detection with Depth Completion.
Focal Sparse Convolutional Networks for 3D Object Detection.
Point-NeRF: Point-based Neural Radiance Fields.
NeRFusion: Fusing Radiance Fields for Large-Scale Scene Reconstruction.
Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction.
Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields.
RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs.
Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields.
Plenoxels: Radiance Fields without Neural Networks.
Neural 3D Scene Reconstruction with the Manhattan-world Assumption.
Neural 3D Video Synthesis from Multi-view Video.
Learning to Solve Hard Minimal Problems.
Learning a Structured Latent Space for Unsupervised Point Cloud Completion.
Lepard: Learning partial point cloud matching in rigid and deformable scenes.
IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images.
Learning Multi-View Aggregation In the Wild for Large-Scale 3D Semantic Segmentation.
HyperDet3D: Learning a Scene-conditioned 3D Object Detector.
KeyTr: Keypoint Transporter for 3D Reconstruction of Deformable Objects in Videos.
SelfRecon: Self Reconstruction Your Digital Avatar from Monocular Video.
Ditto: Building Digital Twins of Articulated Objects from Interaction.
Bijective Mapping Network for Shadow Removal.
Toward Fast, Flexible, and Robust Low-Light Image Enhancement.
Robust Equivariant Imaging: a fully unsupervised framework for learning to image from noisy and partial measurements.
Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution.
Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution.
SphereSR: 360° Image Super-Resolution with Arbitrary Projection via Continuous Spherical Image Representation.
Learning Trajectory-Aware Transformer for Video Super-Resolution.
Discrete Cosine Transform Network for Guided Depth Map Super-Resolution.
Faithful Extreme Rescaling via Generative Prior Reciprocated Invertible Representations.
ELIC: Efficient Learned Image Compression with Unevenly Grouped Space-Channel Contextual Adaptive Coding.
Restormer: Efficient Transformer for High-Resolution Image Restoration.
Deep Rectangling for Image Stitching: A Learning Baseline.
Parametric Scattering Networks.
Burst Image Restoration and Enhancement.
MAXIM: Multi-Axis MLP for Image Processing.
Event-aided Direct Sparse Odometry.
CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation.
Target-aware Dual Adversarial Learning and a Multi-scenario Multi-Modality Benchmark to Fuse Infrared and Visible for Object Detection.
Image Dehazing Transformer with Transmission-Aware 3D Position Embedding.
Unsupervised Deraining: Where Contrastive Learning Meets Self-similarity.
Towards Multi-domain Single Image Dehazing via Test-time Training.
Physically Disentangled Intra- and Inter-domain Adaptation for Varicolored Haze Removal.
Incorporating Semi-Supervised and Positive-Unlabeled Learning for Boosting Full Reference Image Quality Assessment.
Practical Learned Lossless JPEG Recompression with Multi-Level Cross-Channel Entropy Model in the DCT Domain.
Neural Compression-Based Feature Learning for Video Restoration.
Bi-directional Object-Context Prioritization Learning for Saliency Ranking.
URetinex-Net: Retinex-based Deep Unfolding Network for Low-light Image Enhancement.
A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-resolution.
Coarse-To-Fine Deep Video Coding with Hyperprior-Guided Mode Prediction.
Task Decoupled Framework for Reference-based Super-Resolution.
Learning Semantic Associations for Mirror Detection.
SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches.
Investigating Tradeoffs in Real-World Video Super-Resolution.
BasicVSR++: Improving Video Super-Resolution with Enhanced Propagation and Alignment.
Inertia-Guided Flow Completion and Style Fusion for Video Inpainting.
Joint Global and Local Hierarchical Priors for Learned Image Compression.
Reflash Dropout in Image Super-Resolution.
Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond.
Dreaming to Prune Image Deraining Networks.
LC-FDNet: Learned Lossless Image Compression with Frequency Decomposition Network.
Exposure Normalization and Compensation for Multiple-Exposure Correction.
Revisiting Temporal Alignment for Video Restoration.
LSVC: A Learning-based Stereo Video Compression Framework.
Learning based Multi-modality Image and Video Compression.
Transformer Based Line Segment Classifier with Image Context for Real-Time Vanishing Point Detection in Manhattan World.
Deep vanishing point detection: Geometric priors make dataset variations vanish.
Stereo Depth from Events Cameras: Concentrate and Focus on the Future.
Volumetric Bundle Adjustment for Online Photorealistic Scene Capture.
Neural Volumetric Object Selection.
HVH: Learning a Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture.
NeuralHOFusion: Neural Volumetric Rendering under Human-object Interactions.
BNV-Fusion: Dense 3D Reconstruction using Bi-level Neural Volume Fusion.
Input-level Inductive Biases for 3D Reconstruction.
Multi-View Mesh Reconstruction with Neural Deferred Shading.
StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions.
RGB-Depth Fusion GAN for Indoor Depth Completion.
PlanarRecon: Realtime 3D Plane Detection and Reconstruction from Posed Monocular Videos.
Scene Representation Transformer: Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations.
ShapeFormer: Transformer-based Shape Completion via Sparse Representation.
GuideFormer: Transformers for Image Guided Depth Completion.
Improving neural implicit surfaces geometry with patch warping.
Critical Regularizations for Neural Surface Reconstruction in the Wild.
Gradient-SDF: A Semi-Implicit Surface Representation for 3D Reconstruction.
Neural RGB-D Surface Reconstruction.
POCO: Point Convolution for Surface Reconstruction.
Reconstructing Surfaces for Sparse Point Clouds with On-Surface Priors.
Surface Reconstruction from Point Clouds by Learning Predictive Context Priors.
IDEA-Net: Dynamic 3D Point Cloud Interpolation via Deep Embedding Alignment.
Deterministic Point Cloud Registration via Novel Transformation Decomposition.
Global-Aware Registration of Less-Overlap RGB-D Scans.
Finding Good Configurations of Planar Primitives in Unorganized Point Clouds.
Self-Supervised Global-Local Structure Modeling for Point Cloud Domain Adaptation with Reliable Voted Pseudo Labels.
AziNorm: Exploiting the Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception.
WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation.
Forward Propagation, Backward Regression, and Pose Association for Hand Tracking in the Wild.
Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture.
MotionAug: Augmentation with Physical Correction for Human Motion Prediction.
Progressively Generating Better Initial Guesses Towards Next Stages for High-Quality Human Motion Prediction.
Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction.
Motron: Multimodal Probabilistic Human Motion Forecasting.
Human Trajectory Prediction with Momentary Observation.
Non-Probability Sampling Network for Stochastic Human Trajectory Prediction.
Remember Intentions: Retrospective-Memory-based Trajectory Prediction.
GroupNet: Multiscale Hypergraph Neural Networks for Trajectory Prediction with Relational Reasoning.
Learning Pixel Trajectories with Multiscale Contrastive Random Walks.
Adaptive Trajectory Prediction via Transferable GNN.
Neural Prior for Trajectory Estimation.
M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction.
How many Observations are Enough? Knowledge Distillation for Trajectory Forecasting.
ATPFL: Automatic Trajectory Prediction Model Design under Federated Learning Framework.
Whose Track Is It Anyway? Improving Robustness to Tracking Errors with Affinity-based Trajectory Prediction.
Convolutions for Spatial Interaction Modeling.
Style-ERD: Responsive and Coherent Online Motion Style Transfer.
Neural Inertial Localization.
RIO: Rotation-equivariance supervised learning of robust inertial odometry.
CaDeX: Learning Canonical Deformation Coordinate Space for Dynamic Surface Representation via Neural Homeomorphism.
ElePose: Unsupervised 3D Human Pose Estimation by Predicting Camera Elevation and Learning Normalizing Flows on 2D Poses.
Projective Manifold Gradient Layer for Deep Rotation Regression.
Multimodal Colored Point Cloud to Image Alignment.
Multi-instance Point Cloud Registration by Efficient Correspondence Clustering.
REGTR: End-to-end Point Cloud Correspondences with Transformers.
Text2Pos: Text-to-Point-Cloud Cross-Modal Localization.
BCOT: A Markerless High-Precision 3D Object Tracking Benchmark.
SAR-Net: Shape Alignment and Recovery Network for Category-level 6D Object Pose and Size Estimation.
ES6D: A Computation Efficient and Symmetry-Aware 6D Pose Regression Framework.
Coupled Iterative Refinement for 6D Multi-Object Pose Estimation.
ZebraPose: Coarse to Fine Surface Encoding for 6DoF Object Pose Estimation.
SurfEmb: Dense and Continuous Correspondence Distributions for Object Pose Estimation with Learnt Surface Embeddings.
MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision.
Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions.
GPV-Pose: Category-level Object Pose Estimation via Geometry-guided Point-wise Voting.
HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor Space Using Wearable IMUs and LiDAR.
OVE6D: Object Viewpoint Encoding for Depth-based 6D Object Pose Estimation.
FS6D: Few-Shot 6D Pose Estimation of Novel Objects.
OnePose: One-Shot Object Pose Estimation without CAD Models.
OSOP: A Multi-Stage One Shot Object Pose Estimation Framework.
DiffPoseNet: Direct Differentiable Camera Pose Estimation.
Iterative Corresponding Geometry: Fusing Region and Depth for Highly Efficient 3D Tracking of Textureless Objects.
CPPF: Towards Robust Category-Level 9D Pose Estimation in the Wild.
Leveraging Equivariant Features for Absolute Pose Regression.
The Majority Can Help the Minority: Context-rich Minority Oversampling for Long-tailed Classification.
Long- Tailed Recognition via Weight Balancing.
Balanced Contrastive Learning for Long-Tailed Visual Recognition.
Targeted Supervised Contrastive Learning for Long-Tailed Recognition.
Long-tailed Visual Recognition via Gaussian Clouded Logit Adjustment.
Long-tail Recognition via Compositional Knowledge Transfer.
Nested Collaborative Learning for Long-Tailed Visual Recognition.
Retrieval Augmented Classification for Long-Tail Visual Recognition.
Trustworthy Long-Tailed Classification.
C2AM Loss: Chasing a Better Decision Boundary for Long-Tail Object Detection.
Equalized Focal Loss for Dense Long-Tailed Object Detection.
Relieving Long-tailed Instance Segmentation via Pairwise Class Balance.
iFS-RCNN: An Incremental Few-shot Instance Segmenter.
Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling.
SimT: Handling Open-set Noise for Domain Adaptive Semantic Segmentation.
Undoing the Damage of Label Shift for Cross-domain Semantic Segmentation.
Representation Compensation Networks for Continual Semantic Segmentation.
Remember the Difference: Cross-Domain Few-Shot Semantic Segmentation via Meta-Memory Transfer.
Domain-Agnostic Prior for Transfer Semantic Segmentation.
Image Segmentation Using Text and Image Prompts.
PCL: Proxy-based Contrastive Learning for Domain Generalization.
Localized Adversarial Domain Generalization.
Compound Domain Generalization via Meta-Knowledge Encoding.
Style Neophile: Constantly Seeking Novel Styles for Domain Generalization.
Slimmable Domain Adaptation.
Exploring Domain-Invariant Parameters for Source Free Domain Adaptation.
Cross-domain Few-shot Learning with Task-specific Adapters.
Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition.
Reusing the Task-specific Classifier as a Discriminator: Discriminator-free Adversarial Domain Adaptation.
Safe Self-Refinement for Transformer-based Domain Adaptation.
Continual Test-Time Domain Adaptation.
Source-Free Domain Adaptation via Distribution Estimation.
Domain Adaptation on Point Clouds via Geometry-Aware Implicits.
Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds.
Hyperspherical Consistency Regularization.
BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning.
Cascade Transformers for End-to-End Person Search.
Delving Deep into the Generalization of Vision Transformers under Distribution Shifts.
MPViT: Multi-Path Vision Transformer for Dense Prediction.
NFormer: Robust Person Re-identification with Neighbor Transformer.
Part-based Pseudo Label Refinement for Unsupervised Person Re-identification.
Temporal Complementarity-Guided Reinforcement Learning for Image-to-Video Person Re-Identification.
Augmented Geometric Distillation for Data-Free Incremental Person ReID.
Salient-to-Broad Transition for Video Person Re-identification.
FMCNet: Feature-Level Modality Compensation for Visible-Infrared Person Re-Identification.
Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification.
Implicit Sample Extension for Unsupervised Person Re-Identification.
Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection.
Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection.
Fine-Grained Object Classification via Self-Supervised Pose Alignment.
Hyperbolic Vision Transformers: Combining Improvements in Metric Learning.
Non-isotropy Regularization for Proxy-based Deep Metric Learning.
Self-Taught Metric Learning without Labels.
Not Just Selection, but Exploration: Online Class-Incremental Continual Learning via Dual View Consistency.
Energy-based Latent Aligner for Incremental Learning.
Sketch3T: Test-Time Training for Zero-Shot SBIR.
The Devil is in the Pose: Ambiguity-free 3D Rotation-invariant Learning via Pose-aware Convolution.
Finding Badly Drawn Bunnies.
Generalized Category Discovery.
Recall@k Surrogate Loss with Large Batches and Similarity Mixup.
Modeling 3D Layout For Group Re-Identification.
Causal Transportability for Visual Recognition.
Attributable Visual Similarity Learning.
Bi-level Alignment for Cross-Domain Crowd Counting.
Mutual Quantization for Cross-Modal Search with Noisy Labels.
Task Adaptive Parameter Sharing for Multi-Task Learning.
Simple Multi-dataset Detection.
Cross-Domain Adaptive Teacher for Object Detection.
Balanced and Hierarchical Relation Learning for One-shot Object Detection.
Semantic-aligned Fusion Transformer for One-shot Object Detection.
MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning.
Robust Region Feature Synthesizer for Zero-Shot Object Detection.
Region-Aware Face Swapping.
High-resolution Face Swapping via Latent Semantics Disentanglement.
Rethinking Deep Face Restoration.
Blind Face Restoration via Integrating Face Shape and Generative Priors.
FENeRF: Face Editing in Neural Radiance Fields.
TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing.
Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer.
Self-supervised Correlation Mining Network for Person Image Generation.
Exploring Dual-task Correlation for Pose Guided Person Image Generation.
InsetGAN for Full-Body Image Generation.
BodyGAN: General-purpose Controllable Neural Human Body Generation.
HumanNeRF: Efficiently Generated Human Radiance Field from Sparse Inputs.
Structure-Aware Flow Generation for Human Body Reshaping.
Modeling Image Composition for Complex Scene Generation.
Local Attention Pyramid for Scene Image Generation.
Interactive Image Synthesis with Panoptic Layout Generation.
iPLAN: Interactive and Procedural Layout Planning.
E-CIR: Event-Enhanced Continuous Intensity Recovery.
Learning Robust Image-Based Rendering on Sparse Scene Geometry via Depth Completion.
Neural Rays for Occlusion-aware Image-based Rendering.
Industrial Style Transfer with Large-scale Geometric Warping and Content Preservation.
PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models.
Commonality in Natural Images Rescues GANs: Pretraining GANs with Generic and Privacy-free Synthetic Data.
Think Twice Before Detecting GAN-generated Fake Images from their Spectral Domain Imprints.
Robust Invertible Image Steganography.
Distinguishing Unseen from Seen for Generalized Zero-shot Learning.
Few-Shot Font Generation by Learning Fine-Grained Local Styles.
XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation.
Learning to generate line drawings that convey geometry and semantics.
Balanced MSE for Imbalanced Visual Regression.
Transferability Metrics for Selecting Source Model Ensembles.
OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization.
Robust fine-tuning of zero-shot models.
Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification.
Learning to Learn and Remember Super Long Multi-Domain Task Sequence.
Learning Distinctive Margin toward Active Domain Adaptation.
DINE: Domain Adaptation from Single and Multiple Black-box Predictors.
Source-Free Object Detection by Learning to Overlook Domain Style.
Towards Principled Disentanglement for Domain Generalization.
Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization.
Causality Inspired Representation Learning for Domain Generalization.
Learning What Not to Segment: A New Perspective on Few-Shot Segmentation.
Towards Fewer Annotations: Active Learning via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation.
ADeLA: Automatic Dense Labeling with Attention for Viewpoint Shift in Semantic Segmentation.
MeMOT: Multi-Object Tracking with Memory.
Unsupervised Learning of Accurate Siamese Tracking.
Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds.
GMFlow: Learning Optical Flow via Global Matching.
GridShift: A Faster Mode-seeking Algorithm for Image Segmentation and Object Tracking.
SNUG: Self-Supervised Neural Dynamic Garments.
Weakly-supervised Action Transition Learning for Stochastic Human Motion Prediction.
Multi-Objective Diverse Human Motion Prediction with Knowledge Distillation.
Context-Aware Sequence Alignment using 4D Skeletal Augmentation.
Enabling Equivariance for Arbitrary Lie Groups.
RAMA: A Rapid Multicut Algorithm on GPU.
Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks.
RCP: Recurrent Closest Point for Point Cloud.
Audio-Visual Speech Codecs: Rethinking Audio-Visual Speech Enhancement by Re-Synthesis.
Balanced Multimodal Learning via On-the-fly Gradient Modulation.
Block-NeRF: Scalable Large Scene Neural View Synthesis.
SceneSqueezer: Learning to Compress Scene for Camera Relocalization.
Light Field Neural Rendering.
Extracting Triangular 3D Models, Materials, and Lighting From Images.
Super-Fibonacci Spirals: Fast, Low-Discrepancy Sampling of SO(3).
Stochastic Backpropagation: A Memory Efficient Strategy for Training Video Models.
It's All In the Teacher: Zero-Shot Quantization Brought Closer to the Teacher.
NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks.
Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention.
Parameter-free Online Test-time Adaptation.
Patch-level Representation Learning for Self-supervised Vision Transformers.
Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization.
Mixed Differential Privacy in Computer Vision.
DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis.
Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning.
AirObject: A Temporally Evolving Graph Embedding for Object Identification.
Voxel Set Transformer: A Set-to-Set Approach to 3D Object Detection from Point Clouds.
SS3D: Sparsely-Supervised 3D Object Detection from Point Cloud.
Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label Enhancement.
VISTA: Boosting 3D Object Detection via Dual Cross-VIew SpaTial Attention.
Embracing Single Stride 3D Object Detector with Sparse Transformer.
Point Density-Aware Voxels for LiDAR 3D Object Detection.
Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation.
Contrastive Boundary Learning for Point Cloud Segmentation.
Stratified Transformer for 3D Point Cloud Segmentation.
No Pain, Big Gain: Classify Dynamic Point Cloud Sequences with Static Models by Fitting Feature-level Space-time Surfaces.
Point2Seq: Detecting 3D Objects as Sequences.
PTTR: Relational 3D Point Cloud Object Tracking with Transformer.
A Unified Query-based Paradigm for Point Cloud Understanding.
PointCLIP: Point Cloud Understanding by CLIP.
X -Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D Dense Captioning.
MVS2D: Efficient Multiview Stereo via Attention-Driven 2D Convolutions.
TransMVSNet: Global Context-aware Multi-view Stereo Network with Transformers.
RayMVSNet: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo.
IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo.
PSMNet: Position-aware Stereo Merging Network for Room Layout Estimation.
Non-parametric Depth Distribution Modelling based Depth Inference for Multi-view Stereo.
Differentiable Stereopsis: Meshes from multiple views using differentiable rendering.
Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation.
Efficient Multi-view Stereo by Iterative Dynamic Cost Volume.
PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo.
Discrete time convolution for fast event-based stereo.
Stereo Magnification with Multi-Layer Images.
TransforMatcher: Match-to-Match Attention for Semantic Correspondence.
Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences.
Locality-Aware Inter-and Intra-Video Reconstruction for Self-Supervised Correspondence Learning.
Transforming Model Prediction for Tracking.
Ranking-Based Siamese Visual Tracking.
Correlation-Aware Deep Tracking.
Global Tracking via Ensemble of Local Trackers.
Global Tracking Transformers.
Unified Transformer Tracker for Object Tracking.
Transformer Tracking with Cyclic Shifting Window Attention.
Spiking Transformers for Event-based Single Object Tracking.
Adiabatic Quantum Computing for Multi Object Tracking.
HiVT: Hierarchical Vector Transformer for Multi-Agent Motion Prediction.
Towards Discriminative Representation: Multi-view Trajectory Contrastive Learning for Online Multi-object Tracking.
TrackFormer: Multi-Object Tracking with Transformers.
Learning of Global Objective for Network Flow in Multi-Object Tracking.
LMGP: Lifted Multicut Meets Geometry Projections for Multi-Camera Multi-Object Tracking.
Multi-Object Tracking Meets Moving UAV.
Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline.
Unsupervised Domain Adaptation for Nighttime Aerial Tracking.
Learning Optical Flow with Kernel Patch Attention.
Towards Understanding Adversarial Robustness of Optical Flow Networks.
DIP: Deep Inverse Patchmatch for High-Resolution Optical Flow.
On the Instability of Relative Pose Estimation and RANSAC's Role.
Bootstrapping ViTs: Towards Liberating Vision Transformers from Pre-training.
Global Sensing and Measurements Reuse for Image Compressed Sensing.
Maximum Consensus by Weighted Influences of Monotone Boolean Functions.
MS2DG-Net: Progressive Correspondence Learning via Multiple Sparse Semantics Dynamic Graph.
Styleformer: Transformer based Generative Adversarial Networks with Style Vector.
Scanline Homographies for Rolling-Shutter Plane Absolute Pose.
Generating Representative Samples for Few-Shot Classification.
Matching Feature Sets for Few-Shot Image Classification.
Improving Adversarially Robust Few-shot Image Classification with Generalizable Representations.
Sylph: A Hypernetwork Framework for Incremental Few-shot Object Detection.
Forward Compatible Few-Shot Class-Incremental Learning.
Constrained Few-shot Class-incremental Learning.
Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference.
EASE: Unsupervised Discriminant Subspace Learning for Transductive Few-Shot Learning.
Few-shot Learning with Noisy Labels.
Ranking Distance Calibration for Cross-Domain Few-Shot Learning.
Revisiting Learnable Affines for Batch Norm in Few-Shot Transfer Learning.
Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning.
Learning to Memorize Feature Hallucination for One-Shot Image Generation.
A Closer Look at Few-shot Image Generation.
Motion-modulated Temporal Fragment Alignment Network For Few-Shot Action Recognition.
Knowledge Distillation as Efficient Pre-training: Faster Convergence, Higher Data-efficiency, and Better Transferability.
Transferability Estimation using Bhattacharyya Class Separability.
Revisiting the Transferability of Supervised Pretraining: an MLP Perspective.
Task2Sim: Towards Effective Pre-training and Transfer from Synthetic Data.
Which Model to Transfer? Finding the Needle in the Growing Haystack.
Does Robustness on ImageNet Transfer to Downstream Tasks?
What Makes Transfer Learning Work for Medical Images: Feature Reuse & Other Factors.
OW-DETR: Open-world Detection Transformer.
Unseen Classes at a Later Time? No Problem.
Continual Object Detection via Prototypical Task Correlation Guided Gating Mechanism.
On Generalizing Beyond Domains in Cross-Domain Continual Learning.
Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries.
DyTox: Transformers for Continual Learning with DYnamic TOken eXpansion.
Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning.
En-Compactness: Self-Distillation Embedding & Contrastive Generation for Generalized Zero-Shot Learning.
VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning.
Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning.
KG-SP: Knowledge Guided Simple Primitives for Open World Compositional Zero-Shot Learning.
Non-generative Generalized Zero-shot Learning via Task-correlated Disentanglement and Controllable Samples Synthesis.
WALT: Watch And Learn 2D amodal representation from Time-lapse imagery.
Omni-DETR: Omni-Supervised Object Detection with Transformers.
DESTR: Object Detection with Split Transformer.
A Dual Weighting Label Assignment Scheme for Object Detection.
Entropy-based Active Learning for Object Detection with Progressive Diversity Constraint.
Localization Distillation for Dense Object Detection.
Group R-CNN for Weakly Semi-supervised Object Detection with Points.
Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation.
CREAM: Weakly Supervised Object Localization via Class RE-Activation Mapping.
One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching.
PSTR: End-to-End One-Step Person Search With Transformers.
Protecting Celebrities from DeepFake with Identity Consistency Transformer.
MDAN: Multi-level Dependent Attention Network for Visual Emotion Analysis.
Contextual Similarity Distillation for Asymmetric Image Retrieval.
Improving Visual Grounding with Visual-Linguistic Verification and Iterative Reasoning.
MPC: Multi-view Probabilistic Clustering.
Text Spotting Transformers.
Represent, Compare, and Learn: A Similarity-Aware Framework for Class-Agnostic Counting.
Reflection and Rotation Symmetry Detection via Equivariant Learning.
Learning to Imagine: Diversify Memory for Incremental Learning using Unlabeled Data.
A Simple Episodic Linear Probe Improves Visual Recognition in the Wild.
Cross Domain Object Detection by Target-Perceived Dual Branch Distillation.
Multi-Granularity Alignment Domain Adaptation for Object Detection.
Expanding Low-Density Latent Regions for Open-Set Object Detection.
Class-Incremental Learning with Strong Pre-trained Models.
ProposalCLIP: Unsupervised Open-Category Object Proposal Generation via Exploiting CLIP Cues.
Self-Supervised Models are Continual Learners.
The Two Dimensions of Worst-case Training and Their Integrated Effect for Out-of-domain Generalization.
Beyond Supervised vs. Unsupervised: Representative Benchmarking and Analysis of Image Representation Learning.
SimMIM: a Simple Framework for Masked Image Modeling.
Semantic-Aware Auto-Encoders for Self-supervised Representation Learning.
UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning.
Contrastive Conditional Neural Processes.
One-bit Active Query with Contrastive Pairs.
HCSC: Hierarchical Contrastive Selective Coding.
Motion-aware Contrastive Video Representation Learning via Foreground-background Merging.
Hierarchical Self-supervised Representation Learning for Movie Understanding.
Anomaly Detection via Reverse Distillation from One-Class Embedding.
Unsupervised Representation Learning for Binary Networks by Joint Classifier Learning.
DC-SSL: Addressing Mismatched Class Distribution in Semi-supervised Learning.
Learning to Collaborate in Decentralized Learning of Personalized Models.
Highly-efficient Incomplete Largescale Multiview Clustering with Consensus Bipartite Graph.
DASO: Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning.
Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning.
Semi-Supervised Object Detection via Multi-instance Alignment with Global Class Prototypes.
Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free and Anchor-based Detectors.
Spectral Unsupervised Domain Adaptation for Visual Recognition.
DATA: Domain-Aware and Task-Aware Self-supervised Learning.
Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-learning.
DeepDPM: Deep Clustering With an Unknown Number of Clusters.
PLAD: Learning to Infer Shape Programs with Pseudo-Labels and Approximate Distributions.
Robust outlier detection by de-biasing VAE likelihoods.
Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data.
CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding.
Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation.
DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation.
WildNet: Learning Domain Generalized Semantic Segmentation from the Wild.
UCC: Uncertainty guided Cross-head Cotraining for Semi-Supervised Semantic Segmentation.
Semi-supervised Semantic Segmentation with Error Localization Network.
Unbiased Subclass Regularization for Semi-Supervised Semantic Segmentation.
Integrative Few-Shot Learning for Classification and Segmentation.
GANORCON: Are Generative Models Useful for Few-shot Segmentation?
SphericGAN: Semi-supervised Hyper-spherical Generative Adversarial Networks for Fine-grained Image Synthesis.
CoordGAN: Self-Supervised Dense Correspondences Emerge from GANs.
GradViT: Gradient Inversion of Vision Transformers.
Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings.
CD2-pFed: Cyclic Distillation-guided Channel Decoupling for Model Personalization in Federated Learning.
APRIL: Finding the Achilles' Heel on Privacy for Vision Transformers.
Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning.
Robust Federated Learning with Noisy and Heterogeneous Clients.
Federated Learning with Position-Aware Neurons.
Layer-wised Model Aggregation for Personalized Federated Learning.
FedCor: Correlation-Based Active Client Selection Strategy for Heterogeneous Federated Learning.
FedDC: Federated Learning with Non-IID Data via Local Drift Decoupling and Correction.
Differentially Private Federated Learning with Local Regularization and Sparsification.
Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage.
Learn from Others and Be Yourself in Heterogeneous Federated Learning.
RSCFed: Random Sampling Consensus Federated Semi-supervised Learning.
Federated Class-Incremental Learning.
Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning.
FedCorr: Multi-Stage Federated Learning for Label Noise Correction.
ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning.
Cycle-Consistent Counterfactuals by Latent Transformations.
Consistent Explanations by Contrastive Learning.
Towards Better Understanding Attribution Methods.
Proto2Proto: Can you recognize the car, the way I do?
Do Explanations Explain? Model Knows Best.
HINT: Hierarchical Neuron Concept Explainer.
Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes.
What do navigation agents learn about their environment?
A Framework for Learning Ante-hoc Explainable Models via Concepts.
Exploiting Explainable Metrics for Augmented SGD.
FAM: Visual Explanations for the Feature Representations from Deep Convolutional Networks.
Interactive Disentanglement: Learning Concepts by Interacting with their Prototype Representations.
B-cos Networks: Alignment is All We Need for Interpretability.
The Flag Median and FlagIRLS.
Learning Fair Classifiers with Partially Annotated Group Labels.
Estimating Structural Disparities for Face Models.
Estimating Example Difficulty using Variance of Gradients.
Fairness-aware Adversarial Perturbation Towards Bias Mitigation for Deployed Deep Models.
Fair Contrastive Learning for Facial Attribute Classification.
Leveraging Adversarial Examples to Quantify Membership Information Leakage.
Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers.
Deep Unlearning via Randomized Conditionally Independent Hessians.
Equivariance Allows Handling Multiple Nuisance Variables When Analyzing Pooled Neuroimaging Datasets.
A study on the distribution of social biases in self-supervised learning visual models.
Cross-Modal Perceptionist: Can Face Geometry be Gleaned from Voices?
Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation.
SEEG: Semantic Energized Co-speech Gesture Generation.
Mix and Localize: Localizing Sound Sources in Mixtures.
Reading to Listen at the Cocktail Party: Multi-Modal Speech Separation.
IntentVizor: Towards Generic Query Guided Interactive Video Summarization.
M3L: Language-based Video Editing via Multi-Modal Multi-Level Transformers.
Finding Fallen Objects Via Asynchronous Audio-Visual Integration.
Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory.
Egocentric Deep Multi-Channel Audio-Visual Active Speaker Localization.
Audiovisual Generalised Zero-shot Learning with Cross-modal Attention and Language.
It's Time for Artistic Correspondence in Music and Video.
Self-supervised object detection from audio-visual correspondence.
More than Words: In-the-Wild Visually-Driven Prosody for Text-to-Speech.
ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer.
A Probabilistic Graphical Model Based on Neural-symbolic Reasoning for Visual Relationship Detection.
Diffusion Autoencoders: Toward a Meaningful and Decodable Representation.
Polymorphic-GAN: Generating Aligned Samples across Multiple Domains with Learned Morph Maps.
Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values.
Ensembling Off-the-shelf Models for GAN Training.
Marginal Contrastive Correspondence for Guided Image Generation.
GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation.
High-Resolution Image Synthesis with Latent Diffusion Models.
Vector Quantized Diffusion Model for Text-to-Image Synthesis.
ManiTrans: Entity-Level Text-Guided Image Manipulation via Token-wise Semantic Alignment and Generation.
Dataset Distillation by Matching Training Trajectories.
Continual Predictive Learning from Videos.
Motion-Adjustable Neural Implicit Video Representation.
Splicing ViT Features for Semantic Appearance Transfer.
MAT: Mask-Aware Transformer for Large Hole Image Inpainting.
Day-to-Night Image Synthesis for Training Nighttime Neural ISPs.
Smooth-Swap: A Simple Enhancement for Face-Swapping with Smoothness.
Few-Shot Head Swapping in the Wild.
ClothFormer: Taming Video Virtual Try-on in All Module.
A-ViT: Adaptive Tokens for Efficient Vision Transformer.
MetaFormer is Actually What You Need for Vision.
Reversible Vision Transformers.
Learned Queries for Efficient Local Attention.
Shunted Self-Attention via Multi-Scale Token Aggregation.
Automatic Relation-aware Graph Network Proliferation.
β-DARTS: Beta-Decay Regularization for Differentiable Architecture Search.
Distribution Consistent Neural Architecture Search.
Training-free Transformer Architecture Search.
TeachAugment: Data Augmentation Optimization Using Teacher Knowledge.
Knowledge Distillation via the Target-aware Transformer.
Knowledge distillation: A good teacher is patient and consistent.
An Image Patch is a Wave: Phase-Aware Vision MLP.
Dynamic MLP for Fine-Grained Image Classification by Leveraging Geographical and Temporal Information.
Controllable Dynamic Multi-Task Architectures.
Grounded Language-Image Pre-training.
ZZ-Net: A Universal Rotation Equivariant Architecture for 2D Point Clouds.
CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings.
Adversarial Parametric Pose Prior.
Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation.
PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision.
Generalizable Human Pose Triangulation.
GLAMR: Global Occlusion-Aware Human Mesh Recovery with Dynamic Cameras.
Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory.
Contextual Instance Decoupling for Robust Multi-Person Pose Estimation.
End-to-End Multi-Person Pose Estimation with Transformers.
Meta Agent Teaming Active Learning for Pose Estimation.
Keypoint Transformer: Solving Joint Identification in Challenging Hands and Object Interactions for Accurate 3D Pose Estimation.
Not All Tokens Are Equal: Human-centric Visual Analysis via Token Clustering Transformer.
Occlusion-robust Face Alignment using A Viewpoint-invariant Hierarchical Network Architecture.
LASER: LAtent SpacE Rendering for 2D Visual Localization.
Learning to Detect Scene Landmarks for Camera Localization.
Geometric Transformer for Fast and Robust Point Cloud Registration.
ARCS: Accurate Rotation and Correspondence Search.
FisherMatch: Semi-Supervised Rotation Regression via Entropy-based Filtering.
Uni6D: A Unified CNN Framework without Projection Breakdown for 6D Pose Estimation.
OSSGAN: Open-Set Semi-Supervised Image Generation.
Attribute Group Editing for Reliable Few-shot Image Generation.
Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment.
Semantic-shape Adaptive Feature Modulation for Semantic Image Synthesis.
Retrieval-based Spatially Adaptive Normalization for Semantic Image Synthesis.
Generative Flows with Invertible Attentions.
Style-Structure Disentangled Features and Normalizing Flows for Diverse Icon Colorization.
SemanticStyleGAN: Learning Compositional Generative Priors for Controllable Image Synthesis and Editing.
Manifold Learning Benefits GANs.
DO-GAN: A Double Oracle Framework for Generative Adversarial Networks.
Improving GAN Equilibrium by Raising Spatial Awareness.
Feature Statistics Mixing Regularization for Generative Adversarial Networks.
StyleSwin: Transformer-based GAN for High-resolution Image Generation.
MaskGIT: Masked Generative Image Transformer.
StyTr2: Image Style Transfer with Transformers.
Style Transformer for Image Inversion and Editing.
Reduce Information Loss in Transformers for Pluralistic Image Inpainting.
Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding.
UniCoRN: A Unified Conditional Image Repainting Network.
High-Fidelity GAN Inversion for Image Attribute Editing.
HyperInverter: Improving StyleGAN Inversion via Hypernetwork.
Spatially-Adaptive Multilayer Selection for GAN Inversion and Editing.
On Aliased Resizing and Surprising Subtleties in GAN Evaluation.
Dual-path Image Inpainting with Auxiliary GAN Inversion.
InOut: Diverse Image Outpainting via GAN Inversion.
Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation.
Contextual Outpainting with Object-Level Contrastive Learning.
RePaint: Inpainting using Denoising Diffusion Probabilistic Models.
Perception Prioritized Training of Diffusion Models.
Dynamic Dual-Output Diffusion Models.
Generating High Fidelity Data from Low-density Regions using Diffusion Models.
Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation.
Bridging Global Context Interactions for High-Fidelity Image Completion.
Autoregressive Image Generation using Residual Quantization.
Arbitrary-Scale Image Synthesis.
Cluster-guided Image Synthesis with Unconditional Models.
Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation.
Generalized Few-shot Semantic Segmentation.
Learning Non-target Knowledge for Few-shot Semantic Segmentation.
Decoupling Zero-Shot Semantic Segmentation.
Class-Balanced Pixel-Level Self-Labeling for Domain Adaptive Semantic Segmentation.
ContrastMask: Contrastive Learning to Segment Every Thing.
The Neurally-Guided Shape Parser: Grammar-based Labeling of 3D Shape Regions with Approximate Inference.
AutoGPart: Intermediate Supervision Search for Generalizable 3D Part Segmentation.
APES: Articulated Part Extraction from Sprite Sheets.
GASP, a generalized framework for agglomerative clustering of signed graphs and its application to Instance Segmentation.
CycleMix: A Holistic Strategy for Medical Image Segmentation from Scribble Supervision.
Cross-patch Dense Contrastive Learning for Semi-supervised Segmentation of Cellular Nuclei in Histopathologic Images.
C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image.
CRIS: CLIP-Driven Referring Image Segmentation.
MatteFormer: Transformer-Based Image Matting via Prior-Tokens.
Boosting Robustness of Image Matting with Context Assembling and Strong Data Augmentation.
Pyramid Grafting Network for One-Stage High Resolution Saliency Detection.
Multi-Source Uncertainty Mining for Deep Unsupervised Saliency Detection.
Modeling Motion with Multi-Modal Features for Text-Based Video Segmentation.
GAT-CADNet: Graph Attention Network for Panoptic Symbol Spotting in CAD Drawings.
Bending Graphs: Hierarchical Shape Matching using Gated Optimal Transport.
CAPRI-Net: Learning Compact CAD Shapes with Adaptive Primitive Assembly.
RIM-Net: Recursive Implicit Fields for Unsupervised Learning of Hierarchical Shape Structures.
Discovering Objects that Can Move.
PatchFormer: An Efficient Point Transformer with Patch Attention.
Panoptic-PHNet: Towards Real-Time and High-Precision LiDAR Panoptic Segmentation via Clustering Pseudo Heatmap.
SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation.
An MIL-Derived Transformer for Weakly Supervised Point Cloud Segmentation.
Weakly Supervised Segmentation on Outdoor 4D point clouds with Temporal Matching and Spatial Graph Propagation.
Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders.
Demystifying the Neural Tangent Kernel from a Practical Perspective: Can it be trusted for Neural Architecture Search without training?
BaLeNAS: Differentiable Architecture Search via the Bayesian Learning Rule.
Arch-Graph: Acyclic Architecture Relation Predictor for Task-Transferable Neural Architecture Search.
Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search.
GreedyNASv2: Greedier Search with a Greedy Path Filter.
Neural Architecture Search with Representation Mutual Information.
Performance-Aware Mutual Knowledge Distillation for Improving Neural Architecture Search.
Knowledge Distillation with the Reused Teacher Classifier.
Self-Distillation from the Last Mini-Batch for Consistency Regularization.
Decoupled Knowledge Distillation.
Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs.
A ConvNet for the 2020s.
Beyond Fixation: Dynamic Window Visual Transformer.
Lite Vision Transformer with Enhanced Self-Attention.
Swin Transformer V2: Scaling Up Capacity and Resolution.
The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy.
MuIT: An End-to-End Multitask Learning Transformer.
Towards Robust Vision Transformer.
DearKD: Data-Efficient Early Knowledge Distillation for Vision Transformers.
MSG-Transformer: Exchanging Local Spatial Information by Manipulating Messenger Tokens.
NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition.
TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation.
Multi-Scale High-Resolution Vision Transformer for Semantic Segmentation.
Bridged Transformer for Vision and Point Cloud 3D Object Detection.
CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows.
TransMix: Attend to Mix for Vision Transformers.
MiniViT: Compressing Vision Transformers with Weight Multiplexing.
Fine-tuning Image Transformers using Learnable Memory.
Patch Slimming for Efficient Vision Transformers.
CMT: Convolutional Neural Networks Meet Vision Transformers.
Multimodal Token Fusion for Vision Transformers.
CAFE: Learning to Condense Dataset by Aligning Features.
Lite-MDETR: A Lightweight Multi-Modal Detector.
DeeCap: Dynamic Early Exiting for Efficient Image Captioning.
Searching the Deployable Convolution Neural Networks for GPUs.
Active Learning by Feature Mixing.
When to Prune? A Policy towards Early Structural Pruning.
Contrastive Dual Gating: Learning Sparse Features With Contrastive Learning.
How Well Do Sparse ImageNet Models Transfer?
RepNet: Efficient On-Device Learning via Feature Reprogramming.
CHEX: CHannel EXploration for CNN Model Compression.
HODEC: Towards Efficient High-Order DEcomposed Convolutional Neural Networks.
AdaViT: Adaptive Vision Transformers for Efficient Image Recognition.
Cross-Image Relational Knowledge Distillation for Semantic Segmentation.
Mr.BiQ: Post-Training Non-Uniform Quantization based on Minimizing the Reconstruction Error.
IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for Zero-Shot Network Quantization.
DECORE: Deep Compression with Reinforcement Learning.
Towards Efficient and Scalable Sharpness-Aware Minimization.
AEGNN: Asynchronous Event-based Graph Neural Networks.
DiSparse: Disentangled Sparsification for Multitask Model Compression.
Multi-modal Extreme Classification.
A sampling-based approach for efficient clustering in large datasets.
Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction.
Learnable Lookup Table for Neural Network Quantization.
Instance-Aware Dynamic Neural Network Quantization.
Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation.
Fire Together Wire Together: A Dynamic Pruning Approach with Self-Supervised Mask Prediction.
Wavelet Knowledge Distillation: Towards Efficient Image-to-Image Translation.
PokeBNN: A Binary Pursuit of Lightweight Accuracy.
Automated Progressive Learning for Efficient Training of Vision Transformers.
DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos.
Channel Balancing for Accurate Quantization of Winograd Convolutions.
ClusterGNN: Cluster-based Coarse-to-Fine Graph Neural Network for Efficient Feature Matching.
Interspace Pruning: Using Adaptive Filter Representations to Improve Training of Sparse CNNs.
AlignQ: Alignment Quantization with ADMM-based Correlation Preservation.
TVConv: Efficient Translation Variant Convolution for Layout-aware Visual Processing.
SplitNets: Designing Neural Architectures for Efficient Distributed Computing on Head-Mounted Systems.
TO-FLOW: Efficient Continuous Normalizing Flows with Temporal Optimization adjoint with Moving Speed.
DiLiGenT102: A Photometric Stereo Benchmark Dataset with Controlled Shape and Material Variation.
Universal Photometric Stereo Network using Global Lighting Contexts.
Uncertainty-Aware Deep Multi-View Photometric Stereo.
Fast Light-Weight Near-Field Photometric Stereo.
Glass Segmentation using Intensity and Spectral Polarization Cues.
Shape from Polarization for Complex Scenes in the Wild.
Deep Depth from Focus with Differential Focus Volume.
Optimal LED Spectral Multiplexing for NIR2RGB Translation.
Shape from Thermal Radiation: Passive Ranging Using Multi-spectral LWIR Measurements.
NAN: Noise-Aware NeRFs for Burst-Denoising.
Estimating Fine-Grained Noise Model via Contrastive Learning.
Real-time Hyperspectral Imaging in Hardware via Trained Metasurface Encoders.
MNSRNet: Multimodal Transformer Network for 3D Surface Super-Resolution.
PhyIR: Physics-based Inverse Rendering for Panoramic Indoor Images.
Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors.
Learning to Anticipate Future with Dynamic Context Removal.
Self-supervised Spatial Reasoning on Multi-View Line Drawings.
Contextual Debiasing for Visual Recognition with Causal Mechanisms.
Relative Pose from a Calibrated and an Uncalibrated Smartphone Image.
Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation.
NICE-SLAM: Neural Implicit Scalable Encoding for SLAM.
NinjaDesc: Content-Concealing Visual Descriptors via Adversarial Learning.
ScaleNet: A Shallow Architecture for Scale Estimation.
Camera Pose Estimation using Implicit Distortion Models.
GIFS: Neural Implicit Function for General Shape Representation.
Learning Deep Implicit Functions for 3D Shapes with Dynamic Code Clouds.
SPAMs: Structured Implicit Parametric Models.
Deblur-NeRF: Neural Radiance Fields from Blurry Images.
Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation.
Depth-supervised NeRF: Fewer Views and Faster Training for Free.
Dense Depth Priors for Neural Radiance Fields from Sparse Input Views.
EfficientNeRF - Efficient Neural Radiance Fields.
InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering.
Mega-NeRF: Scalable Construction of Large-Scale NeRFs for Virtual Fly- Throughs.
Urban Radiance Fields.
Hallucinated Neural Radiance Fields in the Wild.
Towards Multimodal Depth Estimation from Light Fields.
Degradation-agnostic Correspondence from Resolution-asymmetric Stereo.
Uniform Subdivision of Omnidirectional Camera Space for Efficient Spherical Stereo Matching.
Attention Concatenation Volume for Accurate and Efficient Stereo Matching.
Generalized Binary Search Network for Highly-Efficient Multi-View Stereo.
Revisiting Domain Generalized Stereo Matching Networks from a Feature Consistency Perspective.
GraftNet: Towards Domain Generalized Stereo Matching with a Broad-Spectrum and Task-Oriented Feature.
ITSA: An Information-Theoretic Approach to Automatic Shortcut Avoidance and Domain Generalization in Stereo Matching Networks.
ActiveZero: Mixed Domain Learning for Active Stereovision with Zero Annotation.
FoggyStereo: Stereo Matching with Fog Volume Representation.
Multi-Person Extreme Motion Prediction.
Learning Local-Global Contextual Adaptation for Multi-Person Pose Estimation.
AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation.
Single-Stage is Enough: Multi-Person Absolute 3D Pose Estimation.
Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation.
Trajectory Optimization for Physics-Based Reconstruction of 3d Human Pose from Monocular Video.
Ray3D: ray-based 3D human pose estimation for monocular absolute 3D localization.
Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation.
Location-Free Human Pose Estimation.
MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation.
Estimating Egocentric 3D Human Pose in the Wild with External Weak Supervision.
Physical Inertial Poser (PIP): Physics-aware Real-time Human Motion Tracking from Sparse Inertial Sensors.
PoseKernelLifter: Metric Lifting of 3D Human Pose using Sound.
Differentiable Dynamics for Articulated 3d Human Motion Reconstruction.
COAP: Compositional Articulated Occupancy of People.
Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation from Monocular Video.
SC2-PCR: A Second Order Spatial Compatibility for Efficient and Robust Point Cloud Registration.
MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video.
Putting People in their Place: Monocular Regression of 3D People in Depth.
FLAG: Flow-based 3D Avatar Generation from Sparse Observations.
GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping.
Capturing and Inferring Dense Full-Body Human-Scene Contact.
BodyMap: Learning Full-Body Dense Correspondence Map.
ICON: Implicit Clothed humans Obtained from Normals.
Adversarial Texture for Fooling Person Detectors in the Physical World.
Infrared Invisible Clothing: Hiding from Infrared Detectors at Multiple Angles in Real World.
Enhancing Classifier Conservativeness and Robustness by Polynomiality.
Backdoor Attacks on Self-Supervised Learning.
Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks.
Few-shot Backdoor Defense Using Shapley Estimation.
Better Trigger Inversion Optimization in Backdoor Scanning.
Bandits for Structure Perturbation-based Black-box Attacks to Graph Neural Networks with Theoretical Guarantees.
Improving Robustness Against Stealthy Weight Bit-Flip Attacks by Output Code Matching.
LAS-AT: Adversarial Training with Learnable Attack Strategy.
Subspace Adversarial Training.
Pyramid Adversarial Training Improves ViT Performance.
Fingerprinting Deep Neural Networks Globally via Universal Adversarial Perturbations.
Robust Image Forgery Detection over Online Social Network Shared Images.
Quantifying Societal Bias Amplification in Image Captioning.
Drop the GAN: In Defense of Patches Nearest Neighbors as Single Image Generative Models.
GAN-Supervised Dense Visual Alignment.
Look Closer to Supervise Better: One-Shot Font Generation via Component-Based Discriminator.
Text2Mesh: Text-Driven Neural Stylization for Meshes.
StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation.
Physical Simulation Layer for Accurate 3D Modeling.
Fourier PlenOctrees for Dynamic Radiance Field Rendering in Real-time.
Neural Texture Extraction and Distribution for Controllable Person Image Synthesis.
I M Avatar: Implicit Morphable Head Avatars from Videos.
RCL: Recurrent Continuous Localization for Temporal Action Detection.
Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection.
MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition.
TubeR: Tubelet Transformer for Video Action Detection.
MixFormer: End-to-End Tracking with Iterative Mixed Attention.
DN-DETR: Accelerate DETR Training by Introducing Query DeNoising.
Proper Reuse of Image Classification Features Improves Object Detection.
Boosting 3D Object Detection by Simulating Multimodality on Point Clouds.
TransVPR: Transformer-Based Place Recognition with Multi-Level Attention Aggregation.
Disentangling Visual Embeddings for Attributes and Objects.
QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection.
Unknown-Aware Object Detection: Learning What You Don't Know from Videos in the Wild.
Interpretable part-whole hierarchies and conceptual-semantic relationships in neural networks.
Can Neural Nets Learn the Same Model Twice? Investigating Reproducibility and Double Descent from the Decision Boundary Perspective.
Calibrating Deep Neural Networks by Pairwise Constraints.
Lifelong Graph Learning.
OrphicX: A Causality-Inspired Latent Variable Model for Interpreting Graph Neural Networks.
Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic Manipulation via Discretisation.
Dual Task Learning by Leveraging Both Dense Correspondence and Mis-Correspondence for Robust Change Detection With Imperfect Matches.
Cross-view Transformers for real-time Map-view Semantic Segmentation.
UnweaveNet: Unweaving Activity Stories.
Weakly-Supervised Online Action Segmentation in Multi-View Instructional Videos.
Audio-Adaptive Activity Recognition Across Video Domains.
Frame-wise Action Representations for Long Videos via Sequence Contrastive Learning.
Image Based Reconstruction of Liquids from 2D Surface Detections.
Learning from Untrimmed Videos: Self-Supervised Video Representation Learning with Hierarchical Consistency.
How Do You Do It? Fine-Grained Action Understanding with Pseudo-Adverbs.
Programmatic Concept Learning for Human Motion Description and Synthesis.
Learning To Recognize Procedural Activities with Distant Supervision.
Implicit Motion Handling for Video Camouflaged Object Detection.
Dynamic Scene Graph Generation via Anticipatory Pre-training.
Learning to Refactor Action and Co-occurrence Features for Temporal Action Localization.
OCSampler: Compressing Videos to One Clip with Single-step Sampling.
A Hybrid Egocentric Activity Anticipation Framework via Memory-Augmented Recurrent and One-shot Representation Forecasting.
TubeFormer-DeepLab: Video Mask Transformer.
ASM-Loc: Action-aware Segment Modeling for Weakly-Supervised Temporal Action Localization.
STRPM: A Spatiotemporal Residual Predictive Model for High-Resolution Video Prediction.
Look for the Change: Learning Object States and State-Modifying Actions from Untrimmed Web Videos.
End-to-End Compressed Video Representation Learning for Generic Event Boundary Detection.
Contextualized Spatio-Temporal Contrastive Learning with Self-Supervision.
Deep Anomaly Discovery from Unlabeled Videos via Normality Advantage and Self-Paced Refinement.
A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information.
Long-Short Temporal Contrastive Learning of Video Transformers.
Scene Consistency Representation Learning for Video Scene Segmentation.
Unsupervised Pre-training for Temporal Action Localization Tasks.
Contrastive Learning for Unsupervised Video Highlight Detection.
Deformable Video Transformer.
Recurring the Transformer for Video Action Recognition.
Open-Vocabulary One-Stage Detection with Hierarchical Visual-Language Knowledge Distillation.
Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model.
Sign Language Video Retrieval with Free-Form Textual Queries.
FashionVLP: Vision Language Transformer for Fashion Retrieval with Feedback.
Pushing the Performance Limit of Scene Text Recognizer without Human Annotation.
ESCNet: Gaze Target Detection with the Understanding of 3D Scenes.
Interactive Multi-Class Tiny-Object Detection.
Weakly Supervised Rotation-Invariant Aerial Object Detection Network.
Large Loss Matters in Weakly Supervised Multi-Label Classification.
MetaFSCIL: A Meta-Learning Approach for Few-Shot Class Incremental Learning.
FreeSOLO: Learning to Segment Objects without Annotations.
Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection.
SIOD: Single Instance Annotated Per Category Per Image for Object Detection.
Towards Robust Adaptive Object Detection under Noisy Annotations.
Task-specific Inconsistency Alignment for Domain Adaptive Object Detection.
Salvage of Supervision in Weakly Supervised Object Detection.
Label, Verify, Correct: A Simple Few Shot Object Detection Method.
Background Activation Suppression for Weakly Supervised Object Localization.
Bridging the Gap between Classification and Localization for Weakly Supervised Object Localization.
Divide and Conquer: Compositional Experts for Generalized Novel Class Discovery.
Cloth-Changing Person Re-identification from A Single Image with Gait Prediction and Regularization.
Lifelong Unsupervised Domain Adaptive Person Re-identification with Coordinated Anti-forgetting and Adaptation.
Unleashing Potential of Unsupervised Pre-Training with Intra-Identity Regularization for Person Re-Identification.
Learning with Twin Noisy Labels for Visible-Infrared Person Re-Identification.
Towards Total Recall in Industrial Anomaly Detection.
H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-domain Weakly Supervised Object Detection.
Geometric and Textural Augmentation for Domain Gap Reduction.
General Incremental Learning with Domain-aware Categorical Representations.
DST: Dynamic Substitute Training for Data-free Black-box Attack.
ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation.
Label Matching Semi-Supervised Object Detection.
Multidimensional Belief Quantification for Label-Efficient Meta-Learning.
Propagation Regularizer for Semi-supervised Learning with Extremely Scarce Labeled Samples.
Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification.
Class-Aware Contrastive Semi-Supervised Learning.
Exploring the Equivalence of Siamese Self-Supervised Learning via A Unified Gradient Framework.
Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo.
Learning Where to Learn in Cross-View Self-Supervised Learning.
Dist-PU: Positive-Unlabeled Learning from a Label Distribution Perspective.
SimMatch: Semi-supervised Learning with Similarity Matching.
Active Teacher for Semi-Supervised Object Detection.
Not All Labels Are Equal: Rationalizing The Labeling Costs for Training Object Detection.
Self-Supervised Learning of Object Parts for Semantic Segmentation.
MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection.
Scale-Equivalent Distillation for Semi-Supervised Object Detection.
A Self-Supervised Descriptor for Image Copy Detection.
Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut.
CAD: Co-Adapting Discriminative Features for Improved Few-Shot Classification.
Semi-Supervised Few-shot Learning via Multi-Factor Clustering.
CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning.
Safe-Student for Safe Deep Semi-Supervised Learning with Unseen-Class Unlabeled Data.
A Simple Data Mixing Prior for Improving Self-Supervised Learning.
DETReg: Unsupervised Pretraining with Region Priors for Object Detection.
Sound and Visual Representation Learning with Multiple Pretraining Tasks.
UniVIP: A Unified Framework for Self-Supervised Visual Pre-training.
Weakly Supervised Object Localization as Domain Adaption.
Debiased Learning from Naturally Imbalanced Pseudo-Labels.
Towards Discovering the Effectiveness of Moderately Confident Samples for Semi-Supervised Learning.
Masked Feature Prediction for Self-Supervised Visual Pre-Training.
Contrastive Learning for Space-time Correspondence via Self-cycle Consistency.
Id-Free Person Similarity Learning.
End-to-End Semi-Supervised Learning for Video Action Detection.
Probabilistic Representations for Video Contrastive Learning.
Interact before Align: Leveraging Cross-Modal Knowledge for Domain Adaptive Action Recognition.
BEVT: BERT Pretraining of Video Transformers.
Generative Cooperative Learning for Unsupervised Video Anomaly Detection.
The Norm Must Go On: Dynamic Unsupervised Domain Adaptation by Normalization.
What Matters For Meta-Learning Vision Regression Tasks?
IFOR: Iterative Flow Minimization for Robotic Object Rearrangement.
TCTrack: Temporal Contexts for Aerial Tracking.
AKB-48: A Real-World Articulated Object Knowledge Base.
3DAC: Learning Attribute Compression for Point Clouds.
Simple but Effective: CLIP Embeddings for Embodied AI.
Multi-Robot Active Mapping via Neural Bipartite Graph Matching.
Continuous Scene Representations for Embodied AI.
Interactron: Embodied Adaptive Object Detection.
Online Learning of Reusable Abstract Models for Object Goal Navigation.
RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization.
UDA-COPE: Unsupervised Domain Adaptation for Category-level Object Pose Estimation.
Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation.
Upright-Net: Learning Upright Orientation for 3D Point Cloud.
DeepFake Disrupter: The Detector of DeepFake Is My Friend.
HybridCR: Weakly-Supervised 3D Point Cloud Semantic Segmentation via Hybrid Contrastive Regularization.
Open-Domain, Content-based, Multi-modal Fact-checking of Out-of-Context Images via Online Resources.
Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection.
Segment and Complete: Defending Object Detectors against Adversarial Patch Attacks with Robust Patch Detection.
Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting the Adversarial Transferability.
Improving Adversarial Transferability via Neuron Attribution-based Attacks.
Complex Backdoor Detection by Symmetric Feature Differencing.
Protecting Facial Privacy: Generating Adversarial Identity Masks via Style-robust Makeup Transfer.
Zero-Query Transfer Attacks on Context-Aware Object Detectors.
360-Attack: Distortion-Aware Perturbations from Perspective-Views.
Label-Only Model Inversion Attacks via Boundary Repulsion.
Merry Go Round: Rotate a Frame and Fool a DNN.
Cross-Modal Transferable Adversarial Attacks from Images to Videos.
BppAttack: Stealthy and Efficient Trojan Attacks against Deep Neural Networks via Image Quantization and Contrastive Adversarial Learning.
Investigating Top-k White-Box and Transferable Black-box Attack.
Boosting Black-Box Attack with Partially Transferred Conditional Adversarial Distribution.
Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack.
Towards Efficient Data Free Blackbox Adversarial Attack.
Masking Adversarial Damage: Finding Adversarial Saliency for Robust and Sparse Network.
Certified Patch Robustness via Smoothed Vision Transformers.
Towards Practical Certifiable Patch Defense with Vision Transformer.
On Adversarial Robustness of Trajectory Prediction for Autonomous Vehicles.
3DeformRS: Certifying Spatial Deformations on Point Clouds.
Stereoscopic Universal Perturbations across Different Architectures and Datasets.
Aug-NeRF: Training Stronger Neural Radiance Fields with Triple-Level Physically-Grounded Augmentations.
Bounded Adversarial Attack on Deep Content Features.
DEFEAT: Deep Hidden Feature Backdoor Attacks by Imperceptible Perturbation and Latent Representation Constraints.
Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart.
Give Me Your Attention: Dot-Product Attention Considered Harmful for Adversarial Patch Robustness.
Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input.
Adversarial Eigen Attack on BlackBox Models.
Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond.
Enhancing Adversarial Training with Second-Order Statistics of Weights.
Towards Data-Free Model Stealing in a Hard Label Setting.
Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks with Implicit Gradients.
DTA: Physical Camouflage Attacks using Differentiable Transformation Network.
Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity.
Enhancing Adversarial Robustness for Deep Metric Learning.
Shape-invariant 3D Adversarial Point Clouds.
Shadows can be Dangerous: Stealthy and Effective Physical-world Adversarial Attack by Natural Phenomenon.
Exploring Effective Data for Surrogate Training Towards Black-box Attack.
NICGSlowDown: Evaluating the Efficiency Robustness of Neural Image Caption Generation Models.
Dual-Key Multimodal Backdoors for Visual Question Answering.
Proactive Image Manipulation Detection.
ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts.
Envedit: Environment Editing for Vision-and-Language Navigation.
HOP: History-and-Order Aware Pretraining for Vision-and-Language Navigation.
Less is More: Generating Grounded Navigation Instructions from Landmarks.
Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation.
Reinforced Structured State-Evolution for Vision-Language Navigation.
Cross-modal Map Learning for Vision and Language Navigation.
Counterfactual Cycle-Consistent Learning for Instruction Following and Generation in Vision-Language Navigation.
One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones.
Expanding Large Pre-trained Unimodal Models with Multimodal Information Injection for Image-Text Multimodal Classification.
Shifting More Attention to Visual Backbone: Query-modulated Refinement Networks for End-to-End Visual Grounding.
Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding.
Multi-View Transformer for 3D Visual Grounding.
Multi-Modal Dynamic Graph Transformer for Visual Grounding.
Weakly-Supervised Generation and Grounding of Visual Descriptions with Conditional Generative Models.
Weakly Supervised Temporal Sentence Grounding with Gaussian-based Contrastive Proposal Learning.
Visual Abductive Reasoning.
Query and Attention Augmentation for Knowledge-Based Explainable Reasoning.
REX: Reasoning-aware and Grounded Explanation.
Not All Relations are Equal: Mining Informative Labels for Scene Graph Generation.
Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene Graphs with Language Structures via Dependency Relationships.
Scene Graph Expansion for Semantics-Guided Image Outpainting.
VisualHow: Multimodal Problem Solving.
FLAVA: A Foundational Language And Vision Alignment Model.
Multi-modal Alignment using Representation Codebook.
Negative-Aware Attention Framework for Image-Text Matching.
Vision-Language Pre-Training with Triple Contrastive Learning.
Vision-Language Pre-Training for Boosting Scene Text Detectors.
COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval.
NeurMiPs: Neural Mixture of Planar Experts for View Synthesis.
FWD: Real-time Novel View Synthesis with Forward Warping and Depth.
SOMSI: Spherical Novel View Synthesis with Soft Occlusion Multi-Sphere Images.
Fast, Accurate and Memory-Efficient Partial Permutation Synchronization.
Learning to Find Good Models in RANSAC.
Optimizing Elimination Templates by Greedy Parameter Search.
GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision.
HARA: A Hierarchical Approach for Robust Rotation Averaging.
RAGO: Recurrent Graph Optimizer For Multiple Rotation Averaging.
A Unified Model for Line Projections in Catadioptric Cameras with Rotationally Symmetric Mirrors.
ELSR: Efficient Line Segment Reconstruction with Planes and Points Guidance.
Self-supervised Neural Articulated Shape and Appearance Models.
Virtual Elastic Objects.
Decoupling Makes Weakly Supervised Local Feature Better.
JoinABLe: Learning Bottom-up Assembly of Parametric CAD Joints.
ImplicitAtlas: Learning Deformable Shape Templates in Medical Imaging.
DoubleField: Bridging the Neural Surface and Radiance Fields for High-fidelity Human Reconstruction and Rendering.
Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis.
Structured Local Radiance Fields for Human Avatar Modeling.
High-Fidelity Human Avatars from a Single RGB Camera.
Forecasting Characteristic 3D Poses of Human Actions.
Virtual Correspondence: Humans as a Cue for Extreme-View Geometry.
BEHAVE: Dataset and Method for Tracking Human Object Interactions.
Primitive3D: 3D Object Dataset Synthesis from Randomly Assembled Primitives.
RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation.
NPBG++: Accelerating Neural Point-Based Graphics.
Depth-Guided Sparse Structure-from-Motion for Movies and TV Shows.
Motion-from-Blur: 3D Shape and Motion Estimation of Motion-blurred Objects in Videos.
Masked Autoencoders Are Scalable Vision Learners.
Learning ABCs: Approximate Bijective Correspondence for isolating factors of variation with weak supervision.
Bayesian Invariant Risk Minimization.
Crafting Better Contrastive Views for Siamese Representation Learning.
Rethinking Minimal Sufficient Representation in Contrastive Learning.
Multi-level Feature Learning for Contrastive Multi-view Clustering.
Point-Level Region Contrast for Object Detection Pre-Training.
Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation.
A Stitch in Time Saves Nine: A Train-Time Regularizing Loss for Improved Neural Network Calibration.
SLIC: Self-Supervised Learning with Iterative Clustering for Human Action Videos.
Omnivore: A Single Model for Many Visual Modalities.
DPICT: Deep Progressive Image Compression Using Trit-Planes.
Efficient Geometry-aware 3D Generative Adversarial Networks.
Geometric Anchor Correspondence Mining with Uncertainty Modeling for Universal Domain Adaptation.
Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning.
Versatile Multi-Modal Pre-Training for Human-Centric Perception.
Bridging Video-text Retrieval with Multiple Choice Questions.
Integrating Language Guidance into Vision-based Deep Metric Learning.
NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images.
DIVeR: Real-time and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering.
HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video.
Neural Reflectance for Shape Recovery with Shadow Handling.
Visual Vibration Tomography: Estimating Interior Material Properties from Monocular Video.
Dancing under the stars: video denoising in starlight.
Bacon: Band-limited Coordinate Networks for Multiscale Scene Representation.
Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation.
3D Photo Stylization: Learning to Generate Stylized Novel Views from a Single Image.
BokehMe: When Neural Rendering Meets Classical Rendering.
Deblurring via Stochastic Refinement.
Learning to Deblur using Light Field Generated and Real Defocus Images.
Towards Layer-wise Image Vectorization.
Dual-Shutter Optical Vibration Sensing.
Fisher Information Guidance for Learned Time-of-Flight Imaging.
Autofocus for Event Cameras.
Adaptive Gating for Single-Photon 3D Imaging.
LiDAR Snowfall Simulation for Robust 3D Object Detection.
MERLOT RESERVE: Neural Script Knowledge through Vision and Language and Sound.
Joint Video Summarization and Moment Localization by Cross-Task Sample Transfer.
Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture.
Disentangling visual and written concepts in CLIP.
CLIP-Event: Connecting Text and Images with Event Structures.
Robust Cross-Modal Representation Learning with Progressive Self-Distillation.
TubeDETR: Spatio-Temporal Video Grounding with Transformers.
3D-SPS: Single-Stage 3D Visual Grounding via Referred Point Progressive Selection.
3DJCG: A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds.
Globetrotter: Connecting Languages by Connecting Images.
Unsupervised Vision-and-Language Pretraining via Retrieval-based Multi-Granular Alignment.
WebQA: Multihop and Multimodal QA.
PartGlot: Learning Shape Part Segmentation from Language Reference Games.
DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis.
L-Verse: Bidirectional Generation Between Image and Text.
Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation.
LaTr: Layout-Aware Transformer for Scene-Text VQA.
Learning Program Representations for Food Images and Cooking Recipes.
On the Importance of Asymmetry for Siamese Representation Learning.
Leverage Your Local and Global Representations: A New Self-Supervised Learning Strategy.
Exploring Set Similarity for Dense Self-supervised Representation Learning.
Align Representations with Base: A New Approach to Self-Supervised Learning.
Identifying Ambiguous Similarity Conditions via Semantic Matching.
Node Representation Learning in Graph via Node-to-Neighbourhood Mutual Information Maximization.
Instance-Dependent Label-Noise Learning with Manifold-Regularized Transition Matrix Estimation.
Unsupervised Visual Representation Learning by Online Constrained K-Means.
Rethinking the Augmentation Module in Contrastive Learning: Learning Hierarchical Augmentation Invariance with Expanded Views.
Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework.
Robust Contrastive Learning against Noisy Views.
On Learning Contrastive Representations for Learning with Noisy Labels.
Directional Self-supervised Learning for Heavy Image Augmentations.
Continual Learning for Visual Search with Backward Consistent Feature Embedding.
Probing Representation Forgetting in Supervised and Unsupervised Continual Learning.
Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning.
Bring Evanescent Representations to Life in Lifelong Class Incremental Learning.
Unsupervised Learning of Debiased Representations with Pseudo-Attributes.
A Conservative Approach for Unbiased Learning on Unknown Biases.
Evading the Simplicity Bias: Training a Diverse Set of Models Discovers Solutions with Superior OOD Generalization.
Co-advise: Cross Inductive Bias Distillation.
PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures.
RegionCLIP: Region-based Language-Image Pretraining.
Uni-Perceiver: Pre-training Unified Architecture for Generic Perception for Zero-shot and Few-shot Tasks.
Conditional Prompt Learning for Vision-Language Models.
Noisy Boundaries: Lemon or Lemonade for Semi-supervised Instance Segmentation?
Partial Class Activation Attention for Semantic Segmentation.
Learning Affinity from Attention: End-to-End Weakly-Supervised Semantic Segmentation with Transformers.
Towards Noiseless Object Contours for Weakly Supervised Semantic Segmentation.
Class Similarity Weighted Knowledge Distillation for Continual Semantic Segmentation.
Structural and Statistical Texture Knowledge Distillation for Semantic Segmentation.
L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation.
Weakly Supervised Semantic Segmentation using Out-of-Distribution Data.
Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation.
Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation.
MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation.
NightLab: A Dual-level Architecture with Hardness Detection for Segmentation at Night.
Fast Point Transformer.
RigidFlow: Self-Supervised Scene Flow Learning on Point Clouds by Local Rigidity Prior.
ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes.
DisARM: Displacement Aware Relation Module for 3D Detection.
Learning Object Context for Novel-view Scene Layout Generation.
Weakly But Deeply Supervised Occlusion-Reasoned Parametric Road Layouts.
Beyond Cross-view Image Retrieval: Highly Accurate Vehicle Localization Using Satellite Image.
Raw High-Definition Radar for Multi-Task Learning.
Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation.
UKPGAN: A General Self-Supervised Keypoint Detector.
Cannot See the Forest for the Trees: Aggregating Multiple Viewpoints to Better Classify Objects in Videos.
Rethinking Efficient Lane Detection via Curve Modeling.
Exploiting Temporal Relations on Radar Perception for Autonomous Driving.
Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective.
BE-STI: Spatial-Temporal Integrated Network for Class-agnostic Motion Prediction with Bidirectional Enhancement.
ScePT: Scene-consistent, Policy-based Trajectory Predictions for Planning.
Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion.
Vehicle trajectory prediction works, but not everywhere.
LTP: Lane-based Trajectory Prediction for Autonomous Driving.
ONCE-3DLanes: Building Monocular 3D Lane Detection.
Towards Driving-Oriented Metric for Lane Detection Models.
Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes.
LIFT: Learning 4D LiDAR Image Fusion Transformer for 3D Object Detection.
DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection.
A Versatile Multi-View Framework for LiDAR-based 3D Object Detection with Guidance from Panoptic Segmentation.
Forecasting from LiDAR via Future Object Detection.
RIDDLE: Lidar Data Compression with Range Image Deep Delta Encoding.
Learning from All Vehicles.
Is Mapping Necessary for Realistic PointGoal Navigation?
Symmetry-aware Neural Architecture for Embodied Visual Exploration.
Coopernaut: End-to-End Driving with Cooperative Perception for Networked Vehicles.
Topology Preserving Local Road Network Estimation from Single Onboard Camera Image.
Coupling Vision and Proprioception for Navigation of Legged Robots.
Pyramid Architecture for Multi-Scale Processing in Point Cloud Segmentation.
3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection.
Generating Useful Accident-Prone Driving Scenarios via a Learned Traffic Prior.
SelfD: Self-Learning Large-Scale Driving Policies From the Web.
Towards real-world navigation with deep differentiable planners.
Privacy Preserving Partial Localization.
Efficient Large-scale Localization by Global Instance Recognition.
CrossLoc: Scalable Aerial Localization Assisted by Multimodal Synthetic Data.
Bilateral Video Magnification Filter.
Neural Data-Dependent Transform for Learned Image Compression.
Towards Bidirectional Arbitrary Image Rescaling: Joint Optimization and Cycle Idempotence.
Deep Generalized Unfolding Networks for Image Restoration.
Look Back and Forth: Video Super-Resolution with Explicit Temporal Difference Modeling.
XYDeblur: Divide and Conquer for Single Image Deblurring.
Abandoning the Bayer-Filter to See in the Dark.
RSTT: Real-time Spatial Temporal Transformer for Space-Time Video Super-Resolution.
All-In-One Image Restoration for Unknown Corruption.
Modeling sRGB Camera Noise with Normalizing Flows.
A Differentiable Two-stage Alignment Scheme for Burst Image Reconstruction with Large Shift.
Video Frame Interpolation Transformer.
The Devil Is in the Details: Window-based Attention for Image Compression.
Mask-guided Spectral-wise Transformer for Efficient Hyperspectral Image Reconstruction.
RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs.
AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-time Image Enhancement.
HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging.
HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging.
Learning to Zoom Inside Camera Imaging Pipeline.
Towards An End-to-End Framework for Flow-Guided Video Inpainting.
Context-Aware Video Reconstruction for Rolling Shutter Cameras.
CVF-SID: Cyclic multi-Variate Function for Self-Supervised Image Denoising by Disentangling Noise from Image.
Global Matching with Overlapping Attention for Optical Flow Estimation.
CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow.
Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression.
Video Demoiréing with Relation-Based Temporal Consistency.
Noise2NoiseFlow: Realistic Camera Noise Modeling without Clean Images.
Deep Constrained Least Squares for Blind Image Super-Resolution.
Learning Multiple Adverse Weather Removal via Two-stage Knowledge Learning and Multi-contrastive Regularization: Toward a Unified Model.
Unsupervised Homography Estimation with Coplanarity-Aware GAN.
Attentive Fine-Grained Structured Sparsity for Image Restoration.
Uformer: A General U-Shaped Transformer for Image Restoration.
Bringing Old Films Back to Life.
Learning sRGB-to-Raw-RGB De-rendering with Content-Aware Metadata.
SNR-Aware Low-light Image Enhancement.
AP-BSN: Self-Supervised Denoising for Real-World Images via Asymmetric PD and Blind-Spot Network.
Synthetic Aperture Imaging with Events and Frames.
Ev-TTA: Test-Time Adaptation for Event-Based Object Recognition.
Time Lens++: Event-based Frame Interpolation with Parametric Nonlinear Flow and Multi-scale Fusion.
Unifying Motion Deblurring and Frame Interpolation with Events.
EvUnroll: Neuromorphic Events based Rolling Shutter Image Correction.
Learning Adaptive Warping for RealWorld Rolling Shutter Correction.
Neural Global Shutter: Learn to Restore Video from a Rolling Shutter Camera with Global Reset Feature.
TimeReplayer: Unlocking the Potential of Event Cameras for Video Interpolation.
Optimizing Video Prediction via Video Frame Interpolation.
Reference-based Video Super-Resolution Using Multi-Camera Video Triplets.
Memory-Augmented Non-Local Attention for Video Super-Resolution.
Optical Flow Estimation for Spiking Camera.
Compressive Single-Photon 3D Cameras.
Single-Photon Structured Light.
All-photon Polarimetric Time-of-Flight Imaging.
Holocurtains: Programming Light Curtains via Binary Holography.
Towards Implicit Text-Guided 3D Shape Generation.
Towards Language-Free Training for Text-to-Image Generation.
ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic.
EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching.
Hierarchical Modular Network for Video Captioning.
SwinBERT: End-to-End Transformers with Sparse Attention for Video Captioning.
End-to-end Generative Pretraining for Multimodal Video Captioning.
Beyond a Pre-Trained Object Detector: Cross-Modal Textual and Visual Context for Image Captioning.
Scaling Up Vision-Language Pretraining for Image Captioning.
Comprehending and Ordering Semantics for Image Captioning.
NOC-REK: Novel Object Captioning with Retrieved Vocabulary from External Knowledge.
Injecting Semantic Concepts into End-to-End Image Captioning.
DIFNet: Boosting Visual Information Flow for Image Captioning.
VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning.
Show, Deconfound and Tell: Image Captioning with Causal Inference.
EI-CLIP: Entity-aware Interventional Contrastive Learning for E-commerce Cross-modal Retrieval.
CLIPstyler: Image Style Transfer with a Single Text Condition.
HairCLIP: Design Your Hair by Text and Reference Image.
DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting.
On Guiding Visual Attention with Language Specification.
UTC: A Unified Transformer with Inter-Task Contrastive Learning for Visual Dialog.
Text-to-Image Synthesis based on Object-Guided Joint-Decoding Transformer.
LiT: Zero-Shot Transfer with Locked-image text Tuning.
GroupViT: Semantic Segmentation Emerges from Text Supervision.
ReSTR: Convolution-free Referring Image Segmentation Using Transformers.
LAVT: Language-Aware Vision Transformer for Referring Image Segmentation.
An Empirical Study of Training End-to-End Vision-and-Language Transformers.
Are Multimodal Transformers Robust to Missing Modality?
Text to Image Generation with Semantic-Spatial Aware GAN.
StyleT2I: Toward Compositional and High-Fidelity Text-to-Image Synthesis.
Blended Diffusion for Text-driven Editing of Natural Images.
Make It Move: Controllable Image-to-Video Generation with Text Descriptions.
Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered by Pre-Trained Vision-Language Model.
A Style-aware Discriminator for Controllable Image Translation.
Alleviating Semantics Distortion in Unsupervised Low-Level Image-to-Image Translation via Structure Consistency Constraint.
Exploring Patch-wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks.
FlexIT: Towards Flexible Semantic Image Translation.
Modulated Contrast for Versatile Image Synthesis.
QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation.
Self-Supervised Dense Consistency Regularization for Image-to-Image Translation.
Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image Translation.
InstaFormer: Instance-Aware Image-to-Image Translation with Transformer.
Unsupervised Image-to-Image Translation with Generative Prior.
StylizedNeRF: Consistent 3D Scene Stylization as Stylized NeRF via 2D-3D Mutual Learning.
NeRF-Editing: Geometry Editing of Neural Radiance Fields.
GeoNeRF: Generalizing NeRF with Geometry Priors.
Ray Priors through Reprojection: Improving Neural Radiance Fields for Novel View Extrapolation.
AR-NeRF: Unsupervised Learning of Depth and Defocus Effects from Natural Images with Aperture Rendering Neural Radiance Fields.
HDR-NeRF: High Dynamic Range Neural Radiance Fields.
NeRFReN: Neural Radiance Fields with Reflections.
Neural Point Light Fields.
3D-aware Image Synthesis via Learning Structural and Textural Representations.
GIRAFFE HD: A High-Resolution 3D-aware Generative Model.
Multi-View Consistent Generative Adversarial Networks for 3D-aware Image Synthesis.
Bi-level Doubly Variational Learning for Energy-based Latent Variable Models.
High-Resolution Image Harmonization via Collaborative Dual Transformations.
Brain-Supervised Image Editing.
De-rendering 3D Objects in the Wild.
Neural Fields as Learnable Kernels for 3D Reconstruction.
HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing.
3PSDF: Three-Pole Signed Distance Function for Learning Surfaces with Arbitrary Topologies.
Pop-Out Motion: 3D-Aware Image Deformation via Learning the Shape Laplacian.
Deep Image-based Illumination Harmonization.
PhotoScene: Photorealistic Material and Lighting Transfer for Indoor Scenes.
Neural Template: Topology-aware Reconstruction and Disentangled Generation of 3D Meshes.
Neural Mesh Simplification.
SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning Prediction of Synthetic Characters.
CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation.
UNIST: Unpaired Neural Implicit Shape Translation Network.
CoNeRF: Controllable Neural Radiance Fields.
Neural Points: Point Cloud Representation with Neural Fields for Arbitrary Upsampling.
Modeling Indirect Illumination for Inverse Rendering.
Neural Head Avatars from Monocular RGB Videos.
DeepCurrents: Learning Implicit Representations of Shapes with Boundaries.
Escaping Data Scarcity for High-Resolution Heterogeneous Face Hallucination.
AnyFace: Free-style Text-to-Face Synthesis and Manipulation.
General Facial Representation Learning in a Visual-Linguistic Manner.
Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection.
Detecting Deepfakes with Self-Blended Images.
3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch Feature Swapping for Bodies and Faces.
Evaluation-oriented Knowledge Distillation for Deep Face Recognition.
AdaFace: Quality Adaptive Margin for Face Recognition.
Moving Window Regression: A Novel Approach to Ordinal Regression.
FaceFormer: Speech-Driven 3D Facial Animation with Transformers.
Neural Emotion Director: Speech-preserving semantic control of facial expressions in "in-the-wild" videos.
Deep Decomposition for Stochastic Normal-Abnormal Transport.
DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification.
Node-aligned Graph Convolutional Network for Whole-slide Image Representation and Classification.
Temporal Context Matters: Enhancing Single Image Prediction with Disease Progression Representations.
VRDFormer: End-to-End Video Visual Relation Detection with Transformers.
Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation.
Visual Acoustic Matching.
The Devil is in the Labels: Noisy Label Correction for Robust Scene Graph Generation.
Learning Multiple Dense Prediction Tasks from Partially Annotated Data.
PONI: Potential Functions for ObjectGoal Navigation with Interaction-free Learning.
Continual Stereo Matching of Continuous Driving Scenes with Growing Architecture.
FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation.
Both Style and Fog Matter: Cumulative Domain Adaptation for Semantic Foggy Scene Understanding.
Equivariant Point Cloud Analysis via Learning Orientations for Message Passing.
Surface Representation for Point Clouds.
Not All Points Are Equal: Learning Highly Efficient Point-based Detectors for 3D LiDAR Point Clouds.
3D Common Corruptions and Data Augmentation.
INS-Conv: Incremental Sparse Convolution for Online 3D Segmentation.
How much does input data type impact final face model accuracy?
Ego4D: Around the World in 3, 000 Hours of Egocentric Video.
TransRAC: Encoding Multi-scale Temporal Correlation with Transformers for Repetitive Action Counting.
Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding.
vCLIMB: A Novel Video Class Incremental Learning Benchmark.
Opening up Open World Tracking.
Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions.
CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters.
Failure Modes of Domain Generalization Algorithms.
A Comprehensive Study of Image Classification Model Sensitivity to Foregrounds, Backgrounds, and Visual Attributes.
Grounding Answers for Visual Questions Asked by Visually Impaired People.
Learning to Answer Questions in Dynamic Audio-Visual Scenarios.
Episodic Memory Question Answering.
ScanQA: 3D Question Answering for Spatial Scene Understanding.
Learning Part Segmentation through Unsupervised Domain Adaptation from Synthetic Vehicles.
BTS: A Bi-lingual Benchmark for Text Segmentation in the Wild.
Unified Contrastive Learning in Image-Text-Label Space.
AlignMixup: Improving Representations By Interpolating Aligned Features.
On the Road to Online Adaptation for Semantic Image Segmentation.
ADAS: A Direct Adaptation Strategy for Multi-Target Domain Adaptive Semantic Segmentation.
Kernelized Few-shot Object Detection with Efficient Integral Aggregation.
Neural Mean Discrepancy for Efficient Out-of-Distribution Detection.
A Structured Dictionary Perspective on Implicit Neural Representations.
LARGE: Latent-Based Regression through GAN Semantics.
Rethinking Controllable Variational Autoencoders.
Learning Canonical F-Correlation Projection for Compact Multiview Representation.
Cross-Architecture Self-supervised Video Representation Learning.
Improving Video Model Transfer with Dynamic Representation Learning.
Self-Supervised Image Representation Learning with Geometric Set Consistency.
HLRTF: Hierarchical Low-Rank Tensor Factorization for Inverse Problems in Multi-Dimensional Imaging.
Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling.
DiGS : Divergence guided shape implicit neural representation for unoriented point clouds.
Neural Convolutional Surfaces.
Representing 3D Shapes with Probabilistic Directed Distance Fields.
H4D: Human 4D Modeling by Learning Neural Compositional Representation.
Learning Memory-Augmented Unidirectional Metrics for Cross-modality Person Re-identification.
Contrastive Regression for Domain Adaptation on Gaze Estimation.
Forward Compatible Training for Large-Scale Embedding Retrieval Systems.
Notice of Retraction: E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations.
Improving Subgraph Recognition with Variational Graph Information Bottleneck.
Learning Soft Estimator of Keypoint Scale and Orientation with Probabilistic Covariant Loss.
Few-shot Keypoint Detection with Uncertainty Learning for Unseen Species.
Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.
Structured Sparse R-CNN for Direct Scene Graph Generation.
PPDL: Predicate Probability Distribution based Loss for Unbiased Scene Graph Generation.
RU-Net: Regularized Unrolling Network for Scene Graph Generation.
Fine-Grained Predicates Learning for Scene Graph Generation.
HL-Net: Heterophily Learning Network for Scene Graph Generation.
SGTR: End-to-end Scene Graph Generation with Transformer.
Classification-Then-Grounding: Reformulating Video Scene Graphs as Temporal Bipartite Graphs.
RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition.
Spatial Commonsense Graph for Object Localisation in Partial Scenes.
'The Pedestrian next to the Lamppost" Adaptive Object Graphs for Better Instantaneous Mapping.
Category-Aware Transformer Network for Better Human-Object Interaction Detection.
Exploring Structure-aware Transformer over Interaction Proposals for Human-Object Interaction Detection.
Distillation Using Oracle Queries for Transformer-based Human-Object Interaction Detection.
Human-Object Interaction Detection via Disentangled Transformer.
MSTR: Multi-Scale Transformer for End-to-End Human-Object Interaction Detection.
GaTector: A Unified Framework for Gaze Object Prediction.
STCrowd: A Multimodal Dataset for Pedestrian Perception in Crowded Scenes.
Crowd Counting in the Frequency Domain.
Boosting Crowd Counting via Multifaceted Attention.
Rethinking Spatial Invariance of Convolutional Networks for Object Counting.
Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing.
Collaborative Transformers for Grounded Situation Recognition.
Deep Stereo Image Compression via Bi-directional Coding.
RFNet: Unsupervised Network for Mutually Reinforcing Multi-modal Image Registration and Fusion.
Semi-Supervised Wide-Angle Portraits Correction by Multi-Scale Transformer.
Semi-Supervised Learning of Semantic Correspondence with Pseudo-Labels.
SCS-Co: Self-Consistent Style Contrastive Learning for Image Harmonization.
Automatic Color Image Stitching Using Quaternion Rank-1 Alignment.
SpaceEdit: Learning a Unified Editing Space for Open-Domain Image Color Editing.
Degree-of-linear-polarization-based Color Constancy.
Point Cloud Color Constancy.
Boosting View Synthesis with Residual Transfer.
Deep Hyperspectral-Depth Reconstruction Using Single Color-Dot Projection.
Quantization-aware Deep Optics for Diffractive Snapshot Hyperspectral Imaging.
PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition.
Multimodal Material Segmentation.
Occlusion-Aware Cost Constructor for Light Field Depth Estimation.
Learning Neural Light Fields with Ray-Space Embedding.
Acquiring a Dynamic Light Field through a Single-Shot Coded Image.
Gravitationally Lensed Black Hole Emission Tomography.
Deep Saliency Prior for Reducing Visual Distraction.
Personalized Image Aesthetics Assessment with Rich Attributes.
Artistic Style Discovery with Independent Components.
Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos.
SVIP: Sequence VerIfication for Procedures in Videos.
Set-Supervised Action Learning in Procedural Task Videos via Pairwise Order Consistency.
Exploring Denoised Cross-video Contrast for Weakly-supervised Temporal Action Localization.
GateHUB: Gated History Unit with Background Suppression for Online Action Detection.
E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition.
Hybrid Relation Guided Set Matching for Few-shot Action Recognition.
Spatio-temporal Relation Modeling for Few-shot Action Recognition.
Alignment-Uniformity aware Representation Learning for Zero-shot Video Classification.
Crossmodal Representation Learning for Zero-shot Action Recognition.
Cross-modal Background Suppression for Audio-Visual Event Localization.
Fine-grained Temporal Contrastive Learning for Weakly-supervised Temporal Action Localization.
An Empirical Study of End-to-End Temporal Action Detection.
Everything at Once - Multi-modal Fusion Transformer for Video Retrieval.
DirecFormer: A Directed Attention in Transformer Approach to Robust Action Recognition.
MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection.
Uncertainty-Guided Probabilistic Transformer for Complex Action Recognition.
AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition.
UBoCo: Unsupervised Boundary Contrastive Learning for Generic Event Boundary Detection.
Detector-Free Weakly Supervised Group Activity Recognition.
Multi-grained Spatio-Temporal Features Perceived Network for Event-based Lip-Reading.
Efficient Two-Stage Detection of Human-Object Interactions with a Novel Unary-Pairwise Transformer.
Interactiveness Field in Human-Object Interactions.
GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection.
Object-Relation Reasoning Graph for Action Recognition.
UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection.
Decoupling and Recoupling Spatiotemporal Representation for RGB-D-based Motion Recognition.
SPAct: Self-supervised Privacy Preservation for Action Recognition.
Unsupervised Action Segmentation by Joint Representation Learning and Online Clustering.
InfoGCN: Representation Learning for Human Skeleton-based Action Recognition.
Learning Video Representations of Human Motion from Synthetic Data.
Learnable Irrelevant Modality Dropout for Multimodal Action Recognition on Modality-Specific Annotated Videos.
EyePAD++: A Distillation-based approach for joint Eye Authentication and Presentation Attack Detection using Periocular Images.
Gait Recognition in the Wild with Dense 3D Representations and A Benchmark.
Camera-Conditioned Stable Feature Generation for Isolated Camera Supervised Person Re-IDentification.
Lagrange Motion Analysis and View Embeddings for Improved Gait Recognition.
DeepFace-EMD: Re-ranking Using Patch-wise Earth Mover's Distance Improves Out-Of-Distribution Face Identification.
Learning Second Order Local Anomaly for General Face Forgery Detection.
PatchNet: A Simple Face Anti-Spoofing Framework via Fine-Grained Patch Recognition.
Face2Exp: Combating Data Biases for Facial Expression Recognition.
Local-Adaptive Face Recognition via Graph-based Meta-Clustering and Regularized Adaptation.
EMOCA: Emotion Driven Monocular Face Capture and Animation.
Robust Egocentric Photo-realistic Facial Expression Transfer for Virtual Reality.
FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset.
ImFace: A Nonlinear 3D Morphable Face Model with Implicit Neural Representations.
Physically-guided Disentangled Implicit Rendering for 3D Face Modeling.
RigNeRF: Fully Controllable Neural 3D Portraits.
HeadNeRF: A Realtime NeRF-based Parametric Head Model.
Sparse to Dense Dynamic 3D Facial Expression Generation.
Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion.
Speech Driven Tongue Animation.
Knowledge-Driven Self-Supervised Representation Learning for Facial Action Unit Recognition.
gDNA: Towards Generative Detailed Neural Avatars.
GraFormer: Graph-oriented Transformer for 3D Pose Estimation.
Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose Estimation.
Towards Diverse and Natural Scene-aware 3D Human Motion Synthesis.
PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence.
The Wanderings of Odysseus in 3D Scenes.
OSSO: Obtaining Skeletal Shape from Outside.
LiDARCap: Long-range Markerless 3D Human Motion Capture with LiDAR Point Clouds.
Unimodal-Concentrated Loss: Fully Adaptive Label Distribution Learning for Ordinal Regression.
LISA: Learning Implicit Shape and Appearance of Hands.
MobRecon: Mobile-Friendly Hand Mesh Reconstruction from Monocular Image.
Mining Multi-View Information: A Strong Self-Supervised Framework for Depth-based 3D Hand Pose and Mesh Estimation.
Low-Resource Adaptation for Personalized Co-Speech Gesture Generation.
D-Grasp: Physically Plausible Dynamic Grasp Synthesis for Hand-Object Interactions.
Synthetic Generation of Face Videos with Plethysmograph Physiology.
Contour-Hugging Heatmaps for Landmark Detection.
Which images to label for few-shot medical landmark detection?
Self-Supervised Bulk Motion Artifact Removal in Optical Coherence Tomography Angiography.
Multi-marginal Contrastive Learning for Multilabel Subcellular Protein Localization.
Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-resolution.
Harmony: A Generic Unsupervised Approach for Disentangling Semantic Content from Parameterized Transformations.
Cross-modal Clinical Graph Transformer for Ophthalmic Report Generation.
BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation.
Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis.
Towards Low-Cost and Efficient Malaria Detection.
ACPL: Anti-curriculum Pseudo-labelling for Semi-supervised Medical Image Classification.
Multimodal Dynamics: Dynamical Fusion for Trustworthy Multimodal Classification.
M3T: three-dimensional Medical image classifier using Multi-plane and Multi-slice Transformer.
Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis.
HyperSegNAS: Bridging One-Shot Neural Architecture Search with 3D Medical Image Segmentation using HyperNet.
DArch: Dental Arch Prior-assisted 3D Tooth Instance Segmentation with Weak Annotations.
Clean Implicit 3D Structure from Noisy 2D STEM Images.
Vox2Cortex: Fast Explicit Reconstruction of Cortical Surfaces from 3D MRI Scans with Geometric Deep Neural Networks.
Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning with Pairwise Alignment.
Learning Optimal K-space Acquisition and Reconstruction using Physics-Informed Neural Networks.
NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration.
SMPL-A: Modeling Person-Specific Deformable Anatomy.
DiRA: Discriminative, Restorative, and Adversarial Learning for Self-supervised Medical Image Analysis.
Affine Medical Image Registration with Coarse-to-Fine Vision Transformer.
Topology-Preserving Shape Reconstruction and Registration via Neural Diffeomorphic Flow.
Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization.
Closing the Generalization Gap of Cross-silo Federated Medical Image Segmentation.
FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis.
Surpassing the Human Accuracy: Detecting Gallbladder Cancer from USG Images with Curriculum Learning.
CellTypeGraph: A New Geometric Computer Vision Benchmark.
ContIG: Self-supervised Multimodal Contrastive Learning for Medical Imaging with Genetics.
FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos.
Multi-Dimensional, Nuanced and Subjective - Measuring the Perception of Facial Expressions.
DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D Head Alignment from a Single Image.
OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction.
PoseTrack21: A Dataset for Person Search, Multi-Object Tracking and Multi-Person Pose Tracking.
Learning Modal-Invariant and Temporal-Memory for Video-based Visible-Infrared Person Re-Identification.
JRDB-Act: A Large-scale Dataset for Spatio-temporal Action, Social Group and Activity Detection.
DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion.
Egocentric Prediction of Action Target in 3D.
HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object Interaction.
Amodal Panoptic Segmentation.
Large-scale Video Panoptic Segmentation in the Wild: A Benchmark.
YouMVOS: An Actor-centric Multi-shot Video Object Segmentation Dataset.
The DEVIL is in the Details: A Diagnostic Evaluation Benchmark for Video Inpainting.
3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos.
AxIoU: An Axiomatically Justified Measure for Video Moment Retrieval.
A Large-scale Comprehensive Dataset and Copy-overlap Aware Evaluation Protocol for Segment-level Video Copy Detection.
Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities.
Optimal Correction Cost for Object Detection Evaluation.
GrainSpace: A Large-scale Dataset for Fine-grained and Domain-adaptive Recognition of Cereal Grains.
ABO: Dataset and Benchmarks for Real-World 3D Object Understanding.
Improving Segmentation of the Inferior Alveolar Nerve through Deep Label Propagation.
ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes.
DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation.
Open Challenges in Deep Stereo: the Booster Dataset.
No-Reference Point Cloud Quality Assessment via Domain Adaptation.
Exploring Endogenous Shift for Cross-domain Detection: A Large-scale Benchmark and Perturbation Suppression Network.
How Good Is Aesthetic Ability of a Fashion Model?
Instance-wise Occlusion and Depth Orders in Natural Scenes.
PhoCaL: A Multi-Modal Dataset for Category-Level Object Pose Estimation with Photometrically Challenging Objects.
Replacing Labeled Real-image Datasets with Auto-generated Contours.
V2C: Visual Voice Cloning.
M5Product: Self-harmonized Contrastive Learning for E-commercial Multi-modal Pretraining.
It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection.
From Representation to Reasoning: Towards both Evidence and Commonsense Reasoning for Video Question-Answering.
Point Cloud Pre-training with Natural 3D Structures.
The Auto Arborist Dataset: A Large-Scale Benchmark for Multiview Urban Forest Monitoring Under Domain Shift.
AutoMine: An Unmanned Mine Dataset.
SmartPortraits: Depth Powered Handheld Smartphone Dataset of Human Portraits for State Estimation, Reconstruction and Synthesis.
BigDatasetGAN: Synthesizing ImageNet with Pixel-wise Annotations.
Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task.
Unifying Panoptic Segmentation for Autonomous Driving.
DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection.
SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation.
Ithaca365: Dataset and Driving Perception under Repeated and Challenging Weather Conditions.
SCENIC: A JAX Library for Computer Vision Research and Beyond.
DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides.
VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers.
GeoEngine: A Platform for Production-Ready Geospatial Research.
Talking Face Generation with Multilingual TTS.
Real-Time, Accurate, and Consistent Video Semantic Segmentation via Unsupervised Adaptation and Cross-Unit Deployment on Mobile Device.
BigDL 2.0: Seamless Scaling of AI Pipelines from Laptops to Distributed Cluster.
Interactive Segmentation and Visualization for Tiny Objects in Multi-megapixel Images.
A Low-cost & Realtime Motion Capture System.
PyMiceTracking: An Open-Source Toolbox For Real-Time Behavioral Neuroscience Experiments.
Effective conditioned and composed image retrieval combining CLIP-based features.
VIsCUIT: Visual Auditor for Bias in CNN Image Classifier.
DetectorDetective: Investigating the Effects of Adversarial Examples on Object Detectors.
V-Doc : Visual questions answers with Documents.
Clustering Plotted Data by Image Segmentation.
Spatial-Temporal Parallel Transformer for Arm-Hand Dynamic Estimation.
